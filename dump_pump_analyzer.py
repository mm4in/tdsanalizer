#!/usr/bin/env python3
"""
–ê–ù–ê–õ–ò–ó–ê–¢–û–† –ü–ê–¢–¢–ï–†–ù–û–í –î–õ–Ø –ö–û–ù–¢–†–¢–†–ï–ù–î–û–í–û–ì–û –°–ö–ê–õ–¨–ü–ò–ù–ì–ê
–ó–∞–¥–∞—á–∞: –ù–∞–π—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¥–∞–º–ø/–ø–∞–º–ø —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

–¢–ò–ü–´ –°–û–ë–´–¢–ò–ô:
1. –õ–û–ò —Å –æ—Ç–∫–∞—Ç–∞–º–∏ –í–í–ï–†–• 3%+ (–¥–∞–º–ø ‚Üí –∫–æ–Ω—Ç—Ä—Ç—Ä–µ–Ω–¥ –ø–æ–∫—É–ø–∫–∞)
2. –•–ê–ò —Å –æ—Ç–∫–∞—Ç–∞–º–∏ –í–ù–ò–ó 3%+ (–ø–∞–º–ø ‚Üí –∫–æ–Ω—Ç—Ä—Ç—Ä–µ–Ω–¥ –ø—Ä–æ–¥–∞–∂–∞)  
3. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –¥–∞–º–ø–∞ (–±–µ–∑ –æ—Ç–∫–∞—Ç–æ–≤, —Å–∏–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ)
4. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –ø–∞–º–ø–∞ (–±–µ–∑ –æ—Ç–∫–∞—Ç–æ–≤, —Å–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç)

DATA-DRIVEN –ü–û–î–•–û–î: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –í–°–ï –ø–æ–ª—è –±–µ–∑ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏!
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from advanced_log_parser import AdvancedLogParser
import json
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

class DumpPumpAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∫–æ–Ω—Ç—Ä—Ç—Ä–µ–Ω–¥–æ–≤–æ–≥–æ —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞"""
    
    def __init__(self):
        self.parser = AdvancedLogParser()
        self.data = None
        self.events = []
        self.patterns = {}
        
    def load_and_parse_data(self, file_path: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
        self.data = self.parser.parse_log_file(file_path)
        
        if self.data.empty:
            raise ValueError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.data = self._preprocess_data(self.data)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.data)} –∑–∞–ø–∏—Å–µ–π —Å {len(self.data.columns)} –ø–æ–ª—è–º–∏")
        return self.data
    
    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        if 'timestamp' in df.columns:
            df = df.sort_values('timestamp').reset_index(drop=True)
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
        if 'close' in df.columns:
            df['price_change_pct'] = df['close'].pct_change() * 100
            df['price_change_abs'] = df['close'].diff()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤
        if 'close' in df.columns:
            df['trend_5'] = df['close'].rolling(5).mean().diff() > 0
            df['trend_20'] = df['close'].rolling(20).mean().diff() > 0
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ rolling –º–∏–Ω–∏–º—É–º–æ–≤ –∏ –º–∞–∫—Å–∏–º—É–º–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤
        if 'low' in df.columns and 'high' in df.columns:
            df['rolling_low_5'] = df['low'].rolling(5, center=True).min()
            df['rolling_high_5'] = df['high'].rolling(5, center=True).max()
            df['rolling_low_10'] = df['low'].rolling(10, center=True).min()
            df['rolling_high_10'] = df['high'].rolling(10, center=True).max()
            
            # –õ–æ–∫–∞–ª—å–Ω—ã–µ —ç–∫—Å—Ç—Ä–µ–º—É–º—ã
            df['is_local_low'] = (df['low'] == df['rolling_low_5']) & (df['low'] == df['rolling_low_10'])
            df['is_local_high'] = (df['high'] == df['rolling_high_5']) & (df['high'] == df['rolling_high_10'])
        
        return df
    
    def detect_events(self) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π: –ª–æ–∏/—Ö–∞–∏ —Å –æ—Ç–∫–∞—Ç–∞–º–∏ –∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è"""
        print("üéØ –ü–æ–∏—Å–∫ —Å–æ–±—ã—Ç–∏–π...")
        
        if self.data is None or self.data.empty:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return []
        
        events = []
        
        # –ù–∞—Ö–æ–¥–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã –∏ –º–∞–∫—Å–∏–º—É–º—ã
        lows = self.data[self.data['is_local_low'] == True].copy()
        highs = self.data[self.data['is_local_high'] == True].copy()
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤: {len(lows)}")
        print(f"–ù–∞–π–¥–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤: {len(highs)}")
        
        # –ê–Ω–∞–ª–∏–∑ –ª–æ–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥–∞–º–ø—ã)
        for idx, low_row in lows.iterrows():
            event = self._analyze_low_event(idx, low_row)
            if event:
                events.append(event)
        
        # –ê–Ω–∞–ª–∏–∑ —Ö–∞–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞–º–ø—ã)
        for idx, high_row in highs.iterrows():
            event = self._analyze_high_event(idx, high_row)
            if event:
                events.append(event)
        
        self.events = events
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(events)} —Å–æ–±—ã—Ç–∏–π")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å–æ–±—ã—Ç–∏–π
        event_types = {}
        for event in events:
            event_type = event['type']
            event_types[event_type] = event_types.get(event_type, 0) + 1
        
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–±—ã—Ç–∏–π:")
        for event_type, count in event_types.items():
            print(f"   {event_type}: {count}")
        
        return events
    
    def _analyze_low_event(self, idx: int, low_row: pd.Series) -> Optional[Dict]:
        """–ê–Ω–∞–ª–∏–∑ –ª–æ–∏: –¥–∞–º–ø —Å –æ—Ç–∫–∞—Ç–æ–º –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–∞–¥–µ–Ω–∏—è"""
        
        # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 30 –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ –ª–æ–∏
        next_data = self.data.iloc[idx:idx+30].copy() if idx+30 < len(self.data) else self.data.iloc[idx:].copy()
        
        if len(next_data) < 5:
            return None
        
        low_price = low_row['low']
        
        # –ò—â–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –æ—Ç—Å–∫–æ–∫ –ø–æ—Å–ª–µ –ª–æ–∏
        max_high_after = next_data['high'].max()
        rebound_pct = ((max_high_after - low_price) / low_price) * 100
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è
        if rebound_pct >= 3.0:
            event_type = "low_with_rebound_3pct"
        elif rebound_pct >= 2.0:
            event_type = "low_with_rebound_2pct"
        elif rebound_pct >= 1.0:
            event_type = "low_with_rebound_1pct"
        else:
            event_type = "low_no_rebound"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –º–æ–º–µ–Ω—Ç –ª–æ–∏
        indicators = self._extract_indicators_at_moment(idx)
        
        return {
            'type': event_type,
            'category': 'low_event',
            'index': idx,
            'timestamp': low_row.get('timestamp', ''),
            'price': low_price,
            'rebound_pct': rebound_pct,
            'max_price_after': max_high_after,
            'indicators': indicators
        }
    
    def _analyze_high_event(self, idx: int, high_row: pd.Series) -> Optional[Dict]:
        """–ê–Ω–∞–ª–∏–∑ —Ö–∞–∏: –ø–∞–º–ø —Å –æ—Ç–∫–∞—Ç–æ–º –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–æ—Å—Ç–∞"""
        
        # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 30 –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ö–∞–∏
        next_data = self.data.iloc[idx:idx+30].copy() if idx+30 < len(self.data) else self.data.iloc[idx:].copy()
        
        if len(next_data) < 5:
            return None
        
        high_price = high_row['high']
        
        # –ò—â–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç–∫–∞—Ç –ø–æ—Å–ª–µ —Ö–∞–∏
        min_low_after = next_data['low'].min()
        decline_pct = ((high_price - min_low_after) / high_price) * 100
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è
        if decline_pct >= 3.0:
            event_type = "high_with_decline_3pct"
        elif decline_pct >= 2.0:
            event_type = "high_with_decline_2pct"
        elif decline_pct >= 1.0:
            event_type = "high_with_decline_1pct"
        else:
            event_type = "high_no_decline"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞ –º–æ–º–µ–Ω—Ç —Ö–∞–∏
        indicators = self._extract_indicators_at_moment(idx)
        
        return {
            'type': event_type,
            'category': 'high_event',
            'index': idx,
            'timestamp': high_row.get('timestamp', ''),
            'price': high_price,
            'decline_pct': decline_pct,
            'min_price_after': min_low_after,
            'indicators': indicators
        }
    
    def _extract_indicators_at_moment(self, idx: int) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–±—ã—Ç–∏—è"""
        if idx >= len(self.data):
            return {}
        
        row = self.data.iloc[idx]
        indicators = {}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï –ø–æ–ª—è –∫—Ä–æ–º–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        exclude_fields = {
            'timestamp', 'open', 'high', 'low', 'close', 'volume', 'range',
            'candle_color', 'candle_type', 'line_number', 'raw_line',
            'price_change_pct', 'price_change_abs', 'trend_5', 'trend_20',
            'rolling_low_5', 'rolling_high_5', 'rolling_low_10', 'rolling_high_10',
            'is_local_low', 'is_local_high'
        }
        
        for field in self.data.columns:
            if field not in exclude_fields and not field.endswith('_type'):
                value = row[field]
                if pd.notna(value):  # –¢–æ–ª—å–∫–æ –Ω–µ-NaN –∑–Ω–∞—á–µ–Ω–∏—è
                    indicators[field] = value
        
        return indicators
    
    def analyze_patterns(self) -> Dict:
        """DATA-DRIVEN –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è"""
        print("üß† DATA-DRIVEN –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
        
        if not self.events:
            print("‚ùå –ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return {}
        
        patterns = {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
        events_by_type = {}
        for event in self.events:
            event_type = event['type']
            if event_type not in events_by_type:
                events_by_type[event_type] = []
            events_by_type[event_type].append(event)
        
        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(events_by_type)} —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π...")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
        for event_type, events_list in events_by_type.items():
            if len(events_list) < 3:  # –ú–∏–Ω–∏–º—É–º 3 —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                continue
                
            print(f"\nüìà –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞: {event_type} ({len(events_list)} —Å–æ–±—ã—Ç–∏–π)")
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞
            all_indicators = {}
            for event in events_list:
                for indicator, value in event['indicators'].items():
                    if indicator not in all_indicators:
                        all_indicators[indicator] = []
                    all_indicators[indicator].append(value)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
            indicator_stats = {}
            for indicator, values in all_indicators.items():
                if len(values) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 –∑–Ω–∞—á–µ–Ω–∏—è
                    stats = self._calculate_indicator_statistics(indicator, values)
                    indicator_stats[indicator] = stats
            
            patterns[event_type] = {
                'count': len(events_list),
                'indicator_stats': indicator_stats,
                'events': events_list
            }
        
        self.patterns = patterns
        return patterns
    
    def _calculate_indicator_statistics(self, indicator: str, values: List) -> Dict:
        """–†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞"""
        # –§–∏–ª—å—Ç—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        numeric_values = []
        string_values = []
        
        for value in values:
            if isinstance(value, (int, float)) and not isinstance(value, bool):
                numeric_values.append(value)
            else:
                string_values.append(str(value))
        
        stats = {
            'total_activations': len(values),
            'numeric_count': len(numeric_values),
            'string_count': len(string_values)
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if numeric_values:
            numeric_values = np.array(numeric_values)
            stats.update({
                'mean': float(np.mean(numeric_values)),
                'median': float(np.median(numeric_values)),
                'std': float(np.std(numeric_values)),
                'min': float(np.min(numeric_values)),
                'max': float(np.max(numeric_values)),
                'activation_rate': len(numeric_values) / len(values)
            })
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if string_values:
            from collections import Counter
            value_counts = Counter(string_values)
            stats['string_patterns'] = dict(value_counts)
        
        return stats
    
    def find_discriminative_patterns(self) -> Dict:
        """–ü–æ–∏—Å–∫ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –º–µ–∂–¥—É —Ç–∏–ø–∞–º–∏ —Å–æ–±—ã—Ç–∏–π"""
        print("üîç –ü–æ–∏—Å–∫ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
        
        if not self.patterns:
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ analyze_patterns()")
            return {}
        
        discriminative = {}
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø—ã —Å–æ–±—ã—Ç–∏–π
        comparison_pairs = [
            ("low_with_rebound_3pct", "low_no_rebound"),
            ("high_with_decline_3pct", "high_no_decline"),
            ("low_with_rebound_3pct", "high_with_decline_3pct")
        ]
        
        for type1, type2 in comparison_pairs:
            if type1 in self.patterns and type2 in self.patterns:
                diff = self._compare_pattern_types(type1, type2)
                discriminative[f"{type1}_vs_{type2}"] = diff
        
        return discriminative
    
    def _compare_pattern_types(self, type1: str, type2: str) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        pattern1 = self.patterns[type1]['indicator_stats']
        pattern2 = self.patterns[type2]['indicator_stats']
        
        differences = {}
        
        # –û–±—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        common_indicators = set(pattern1.keys()) & set(pattern2.keys())
        
        for indicator in common_indicators:
            stats1 = pattern1[indicator]
            stats2 = pattern2[indicator]
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if 'mean' in stats1 and 'mean' in stats2:
                mean_diff = abs(stats1['mean'] - stats2['mean'])
                activation_diff = abs(stats1.get('activation_rate', 0) - stats2.get('activation_rate', 0))
                
                # –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å —Ä–∞–∑–ª–∏—á–∏–º–æ—Å—Ç–∏
                discriminative_power = mean_diff + activation_diff * 10
                
                if discriminative_power > 0.5:  # –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    differences[indicator] = {
                        'mean_diff': mean_diff,
                        'activation_diff': activation_diff,
                        'discriminative_power': discriminative_power,
                        f'{type1}_mean': stats1['mean'],
                        f'{type2}_mean': stats2['mean'],
                        f'{type1}_activation': stats1.get('activation_rate', 0),
                        f'{type2}_activation': stats2.get('activation_rate', 0)
                    }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω–æ–π —Å–∏–ª–µ
        sorted_differences = dict(sorted(differences.items(), 
                                       key=lambda x: x[1]['discriminative_power'], 
                                       reverse=True))
        
        return sorted_differences
    
    def find_veto_patterns(self) -> Dict:
        """–ü–æ–∏—Å–∫ VETO –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ - –ø–æ–ª–µ–π –±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö –ª–æ–∂–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã"""
        print("üö´ –ü–æ–∏—Å–∫ VETO –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
        
        if not self.patterns:
            return {}
        
        veto_patterns = {}
        
        # –ò—â–µ–º –ø–æ–ª—è –∫–æ—Ç–æ—Ä—ã–µ –∞–∫—Ç–∏–≤–Ω—ã –≤ "–ø–ª–æ—Ö–∏—Ö" —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö –∏ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã –≤ "—Ö–æ—Ä–æ—à–∏—Ö"
        good_events = ['low_with_rebound_3pct', 'high_with_decline_3pct']
        bad_events = ['low_no_rebound', 'high_no_decline']
        
        for good_type in good_events:
            for bad_type in bad_events:
                if good_type in self.patterns and bad_type in self.patterns:
                    veto_fields = self._find_veto_fields(good_type, bad_type)
                    if veto_fields:
                        veto_patterns[f"{good_type}_blocked_by"] = veto_fields
        
        return veto_patterns
    
    def _find_veto_fields(self, good_type: str, bad_type: str) -> Dict:
        """–ü–æ–∏—Å–∫ –ø–æ–ª–µ–π –±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö —Ö–æ—Ä–æ—à–∏–µ —Å–∏–≥–Ω–∞–ª—ã"""
        good_stats = self.patterns[good_type]['indicator_stats']
        bad_stats = self.patterns[bad_type]['indicator_stats']
        
        veto_fields = {}
        
        for indicator in set(good_stats.keys()) | set(bad_stats.keys()):
            good_activation = good_stats.get(indicator, {}).get('activation_rate', 0)
            bad_activation = bad_stats.get(indicator, {}).get('activation_rate', 0)
            
            # VETO –ø–æ–ª–µ: –∞–∫—Ç–∏–≤–Ω–æ –≤ –ø–ª–æ—Ö–∏—Ö —Å–æ–±—ã—Ç–∏—è—Ö, –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ –≤ —Ö–æ—Ä–æ—à–∏—Ö
            if bad_activation > 0.7 and good_activation < 0.3:
                veto_fields[indicator] = {
                    'good_activation': good_activation,
                    'bad_activation': bad_activation,
                    'veto_strength': bad_activation - good_activation
                }
        
        return veto_fields
    
    def generate_simple_tables(self) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö —Ç–∞–±–ª–∏—Ü '–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä ‚Üí —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è'"""
        print("üìã –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö —Ç–∞–±–ª–∏—Ü...")
        
        if not self.patterns:
            return {}
        
        tables = {}
        
        # –¢–æ–ø –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∏–ø—É —Å–æ–±—ã—Ç–∏—è
        for event_type, pattern_data in self.patterns.items():
            indicator_stats = pattern_data['indicator_stats']
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–∞–∫—Ç–∏–≤–∞—Ü–∏—è + –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ)
            ranked_indicators = []
            for indicator, stats in indicator_stats.items():
                if 'mean' in stats and 'activation_rate' in stats:
                    importance = stats['activation_rate'] * (1 + abs(stats['mean']))
                    ranked_indicators.append({
                        'indicator': indicator,
                        'mean': stats['mean'],
                        'activation_rate': stats['activation_rate'],
                        'importance': importance,
                        'activations': stats['total_activations']
                    })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            ranked_indicators.sort(key=lambda x: x['importance'], reverse=True)
            
            tables[event_type] = ranked_indicators[:20]  # –¢–æ–ø 20
        
        return tables
    
    def save_results(self, output_dir: str = "results/dump_pump_analysis"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ {output_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è
        if self.events:
            events_df = pd.DataFrame([
                {
                    'type': event['type'],
                    'category': event['category'],
                    'timestamp': event['timestamp'],
                    'price': event['price'],
                    'change_pct': event.get('rebound_pct', event.get('decline_pct', 0)),
                    'indicator_count': len(event['indicators'])
                }
                for event in self.events
            ])
            events_df.to_csv(output_path / "events_summary.csv", index=False)
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å–≤–æ–¥–∫–∞ —Å–æ–±—ã—Ç–∏–π: {len(events_df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if self.patterns:
            with open(output_path / "patterns_analysis.json", 'w', encoding='utf-8') as f:
                json.dump(self.patterns, f, indent=2, ensure_ascii=False, default=str)
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Ç–∞–±–ª–∏—Ü—ã
        simple_tables = self.generate_simple_tables()
        if simple_tables:
            with open(output_path / "simple_tables.json", 'w', encoding='utf-8') as f:
                json.dump(simple_tables, f, indent=2, ensure_ascii=False, default=str)
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ø—Ä–æ—Å—Ç—ã–µ —Ç–∞–±–ª–∏—Ü—ã")
        
        # –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        discriminative = self.find_discriminative_patterns()
        if discriminative:
            with open(output_path / "discriminative_patterns.json", 'w', encoding='utf-8') as f:
                json.dump(discriminative, f, indent=2, ensure_ascii=False, default=str)
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        
        # VETO –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        veto_patterns = self.find_veto_patterns()
        if veto_patterns:
            with open(output_path / "veto_patterns.json", 'w', encoding='utf-8') as f:
                json.dump(veto_patterns, f, indent=2, ensure_ascii=False, default=str)
            print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã VETO –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç—á–µ—Ç
        self._create_readable_report(output_path)
        
        return output_path
    
    def _create_readable_report(self, output_path: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–Ω—è—Ç–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report_lines = [
            "# –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í –î–ê–ú–ü/–ü–ê–ú–ü",
            "=" * 50,
            "",
            f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(self.data) if self.data is not None else 0}",
            f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {len(self.events)}",
            "",
            "## –¢–ò–ü–´ –°–û–ë–´–¢–ò–ô",
            ""
        ]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å–æ–±—ã—Ç–∏–π
        if self.events:
            event_counts = {}
            for event in self.events:
                event_type = event['type']
                event_counts[event_type] = event_counts.get(event_type, 0) + 1
            
            for event_type, count in sorted(event_counts.items()):
                report_lines.append(f"{event_type}: {count} —Å–æ–±—ã—Ç–∏–π")
        
        # –¢–æ–ø –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ —Ç–∏–ø–∞–º
        if self.patterns:
            simple_tables = self.generate_simple_tables()
            
            for event_type, indicators in simple_tables.items():
                report_lines.extend([
                    "",
                    f"## –¢–û–ü –ò–ù–î–ò–ö–ê–¢–û–†–´ –î–õ–Ø {event_type.upper()}",
                    ""
                ])
                
                for i, indicator_data in enumerate(indicators[:10], 1):
                    indicator = indicator_data['indicator']
                    mean = indicator_data['mean']
                    activation = indicator_data['activation_rate']
                    
                    report_lines.append(
                        f"{i:2d}. {indicator:15s} | "
                        f"—Å—Ä–µ–¥–Ω–µ–µ: {mean:8.2f} | "
                        f"–∞–∫—Ç–∏–≤–∞—Ü–∏—è: {activation:5.1%} | "
                        f"—Å–æ–±—ã—Ç–∏–π: {indicator_data['activations']}"
                    )
        
        # –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        discriminative = self.find_discriminative_patterns()
        if discriminative:
            report_lines.extend([
                "",
                "## –†–ê–ó–õ–ò–ß–ê–Æ–©–ò–ï –ü–ê–¢–¢–ï–†–ù–´",
                ""
            ])
            
            for comparison, patterns in discriminative.items():
                report_lines.append(f"### {comparison}")
                
                for indicator, data in list(patterns.items())[:5]:
                    report_lines.append(
                        f"  {indicator}: —Å–∏–ª–∞ —Ä–∞–∑–ª–∏—á–∏—è = {data['discriminative_power']:.2f}"
                    )
                report_lines.append("")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        with open(output_path / "readable_report.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç—á–µ—Ç")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–º–ø/–ø–∞–º–ø –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    print("üöÄ –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –î–ê–ú–ü/–ü–ê–ú–ü –ü–ê–¢–¢–ï–†–ù–û–í")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = DumpPumpAnalyzer()
    
    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
    data_file = "data/dslog_btc_0508240229_ltf.txt"
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
        print("\n1Ô∏è‚É£ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
        data = analyzer.load_and_parse_data(data_file)
        
        # 2. –ü–æ–∏—Å–∫ —Å–æ–±—ã—Ç–∏–π
        print("\n2Ô∏è‚É£ –ü–û–ò–°–ö –°–û–ë–´–¢–ò–ô")
        events = analyzer.detect_events()
        
        if not events:
            print("‚ùå –°–æ–±—ã—Ç–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
            return
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        print("\n3Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í")
        patterns = analyzer.analyze_patterns()
        
        # 4. –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        print("\n4Ô∏è‚É£ –î–ò–°–ö–†–ò–ú–ò–ù–ê–¢–ò–í–ù–´–ô –ê–ù–ê–õ–ò–ó")
        discriminative = analyzer.find_discriminative_patterns()
        
        # 5. VETO –∞–Ω–∞–ª–∏–∑
        print("\n5Ô∏è‚É£ VETO –ê–ù–ê–õ–ò–ó")
        veto_patterns = analyzer.find_veto_patterns()
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n6Ô∏è‚É£ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        output_path = analyzer.save_results()
        
        print(f"\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
        print(f"üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: {output_path}/readable_report.txt")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
