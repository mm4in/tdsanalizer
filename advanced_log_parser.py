#!/usr/bin/env python3
"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–ê–†–°–ï–† –õ–û–ì–û–í - –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –í–°–ï–• –ò–ù–î–ò–ö–ê–¢–û–†–ù–´–• –ü–û–õ–ï–ô
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (ef2--7.19, ze2--4.12)

–ò–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï –ø–æ–ª—è –∏–∑ —Å—ã—Ä–æ–≥–æ –ª–æ–≥–∞:
- nw (—Å–∏–≥–Ω–∞–ª—ã !!, !!!) 
- ef (energy factor) —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
- as (accumulated signal)
- vc (volatility composite)
- ze (zero crossing) —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
- maz, cvz, dz, rz, mz (sigma –ø–æ–ª—è)
- co, ro, mo, do, so (momentum –ø–æ–ª—è)
"""

import re
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime

class AdvancedLogParser:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –í–°–ï–• –ø–æ–ª–µ–π –∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ª–æ–≥–æ–≤
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
        self.field_patterns = self._create_field_patterns()
        self.metadata_patterns = self._create_metadata_patterns()
        self.parsed_data = []
        self.field_statistics = {}
        
    def _create_field_patterns(self) -> Dict[str, str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –ø–æ–ª–µ–π –∏–∑ –¢–ó
        self.ltf_field_prefixes = {
            'rd', 'md', 'cd', 'cmd', 'macd', 'cvd', 'dd', 'ed', 'sd', 
            'ro', 'mo', 'co', 'cz', 'do', 'so', 'rz', 'mz', 'ciz', 'sz', 
            'dz', 'cvz', 'maz', 'ef', 'vc', 'ze', 'nw', 'as', 'vw'
        }
        
        self.htf_field_prefixes = {
            'rd', 'md', 'cd', 'cmd', 'macd', 'od', 'dd', 'cvd', 'drd', 'ad',
            'ed', 'hd', 'sd', 'ro', 'mo', 'co', 'cz', 'do', 'ae', 'so',
            'rz', 'mz', 'ciz', 'sz', 'dz', 'ef', 'wv', 'vc', 'ze', 'nw',
            'dz', 'cvz', 'maz', 'oz'
        }
        
        self.special_htf_fields = {'bs', 'wa', 'pd'}
        
        # –°—É—Ñ—Ñ–∏–∫—Å—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è LTF/HTF
        self.ltf_suffixes = {'2', '5', '15', '30'}
        self.htf_suffixes = {'1h', '4h', '1d', '1w'}
        
        patterns = {
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª–µ–π –¥–∞–Ω–Ω—ã—Ö
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç: ef2--7.19, nw2-!!, as2-3.33, ze2--4.12
            'universal_field': r'([a-zA-Z]+)(\d+|1h|4h|1d|1w)-((?:!+)|(?:--?\d+(?:\.\d+)?(?:%)?)|(?:-?\d+(?:\.\d+)?(?:%)?))',
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ HTF –ø–æ–ª—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤
            'special_htf': r'\b(bs|wa|pd)\b(?:\s+([^\s,|]+))?',
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑—Ä–µ–ª–æ—Å—Ç–∏ (progress –ø–æ–ª—è)
            'progress_ltf': r'p(\d+)-(-?\d+(?:\.\d+)?)',
            'progress_htf': r'p(1h|4h|1d|1w)-(-?\d+(?:\.\d+)?)',
        }
        return patterns
    
    def _create_metadata_patterns(self) -> Dict[str, str]:
        """–ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π (–≤—Ç–æ—Ä–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)"""
        return {
            'timestamp': r'\[([^\]]+)\]',
            'ohlc': r'o:([0-9.]+)\|h:([0-9.]+)\|l:([0-9.]+)\|c:([0-9.]+)',
            'volume': r'\|([0-9.]+K)\|',
            'range': r'rng:([0-9.]+)',
            'candle_type': r'\|(NORMAL|BIG_BODY|DOJI|HAMMER|PIN_TOP|FLAT)\|',
            'color': r'\|(RED|GREEN)\|',
            'change_24h': r'(-?\d+(?:\.\d+)?)%_24h'
        }
    
    def parse_log_file(self, file_path: str) -> pd.DataFrame:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –í–°–ï–• –ø–æ–ª–µ–π
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞
            
        Returns:
            DataFrame —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
        """
        print(f"üîç –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–∞: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(lines)} —Å—Ç—Ä–æ–∫")
        
        parsed_records = []
        
        for i, line in enumerate(lines):
            try:
                record = self._parse_single_line(line.strip(), i)
                if record:
                    parsed_records.append(record)
                    
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if (i + 1) % 1000 == 0:
                    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i + 1}/{len(lines)} —Å—Ç—Ä–æ–∫")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {i}: {str(e)[:100]}")
                continue
        
        if not parsed_records:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–æ–≥–∞")
            return pd.DataFrame()
        
        df = pd.DataFrame(parsed_records)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
        self._generate_parsing_statistics(df)
        
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π —Å {len(df.columns)} –ø–æ–ª—è–º–∏")
        return df
    
    def _parse_single_line(self, line: str, line_num: int) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞"""
        if not line or line.startswith('#'):
            return None
        
        record = {'line_number': line_num, 'raw_line': line}
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = self._extract_metadata(line)
        record.update(metadata)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –í–°–ï–• –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ª–µ–π
        indicator_fields = self._extract_all_indicator_fields(line)
        record.update(indicator_fields)
        
        return record
    
    def _extract_metadata(self, line: str) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–∏"""
        metadata = {}
        
        # Timestamp
        ts_match = re.search(self.metadata_patterns['timestamp'], line)
        if ts_match:
            metadata['timestamp'] = ts_match.group(1)
        
        # OHLC
        ohlc_match = re.search(self.metadata_patterns['ohlc'], line)
        if ohlc_match:
            metadata['open'] = float(ohlc_match.group(1))
            metadata['high'] = float(ohlc_match.group(2))
            metadata['low'] = float(ohlc_match.group(3))
            metadata['close'] = float(ohlc_match.group(4))
        
        # Volume
        vol_match = re.search(r'\|([0-9.]+)K\|', line)
        if vol_match:
            metadata['volume'] = float(vol_match.group(1))
        
        # Range
        rng_match = re.search(r'rng:([0-9.]+)', line)
        if rng_match:
            metadata['range'] = float(rng_match.group(1))
        
        # Candle type and color
        if 'RED' in line:
            metadata['candle_color'] = 'RED'
        elif 'GREEN' in line:
            metadata['candle_color'] = 'GREEN'
            
        if 'BIG_BODY' in line:
            metadata['candle_type'] = 'BIG_BODY'
        elif 'DOJI' in line:
            metadata['candle_type'] = 'DOJI'
        elif 'HAMMER' in line:
            metadata['candle_type'] = 'HAMMER'
        elif 'PIN_TOP' in line:
            metadata['candle_type'] = 'PIN_TOP'
        elif 'FLAT' in line:
            metadata['candle_type'] = 'FLAT'
        else:
            metadata['candle_type'] = 'NORMAL'
        
        return metadata
    
    def _extract_all_indicator_fields(self, line: str) -> Dict:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–ª–µ–π –¥–∞–Ω–Ω—ã—Ö"""
        fields = {}
        
        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–ª–µ–π —Ñ–æ—Ä–º–∞—Ç–∞ prefix+suffix-value
        universal_matches = re.findall(self.field_patterns['universal_field'], line)
        
        for prefix, suffix, value in universal_matches:
            field_name = f"{prefix}{suffix}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–ª—è (LTF/HTF) –ø–æ —Å—É—Ñ—Ñ–∏–∫—Å—É
            is_ltf = suffix in self.ltf_suffixes
            is_htf = suffix in self.htf_suffixes
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–µ—Ñ–∏–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å–ø–∏—Å–∫–∞—Ö
            valid_ltf = is_ltf and prefix in self.ltf_field_prefixes
            valid_htf = is_htf and prefix in self.htf_field_prefixes
            
            if valid_ltf or valid_htf:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ nw (!!!, !!)
                if prefix == 'nw' and '!' in value:
                    fields[field_name] = len(value)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ !
                    fields[f"{field_name}_signal"] = value  # –°–∞–º —Å–∏–≥–Ω–∞–ª
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–≤–∫–ª—é—á–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å –¥–≤–æ–π–Ω—ã–º–∏ –¥–µ—Ñ–∏—Å–∞–º–∏)
                elif self._is_numeric_value(value):
                    try:
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —á–∏—Å–ª–æ
                        numeric_value = self._parse_numeric_value(value)
                        fields[field_name] = numeric_value
                        
                        # –ú–∞—Ä–∫–∏—Ä–æ–≤–∫–∞ —Ç–∏–ø–∞ –ø–æ–ª—è
                        if is_ltf:
                            fields[f"{field_name}_type"] = 'LTF'
                        elif is_htf:
                            fields[f"{field_name}_type"] = 'HTF'
                            
                    except ValueError:
                        # –ï—Å–ª–∏ –Ω–µ —á–∏—Å–ª–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                        fields[field_name] = value
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                else:
                    fields[field_name] = value
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ HTF –ø–æ–ª—è (bs, wa, pd)
        special_matches = re.findall(self.field_patterns['special_htf'], line)
        for field, value in special_matches:
            if field in self.special_htf_fields:
                fields[field] = value if value else 1  # 1 –µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                fields[f"{field}_type"] = 'HTF_SPECIAL'
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑—Ä–µ–ª–æ—Å—Ç–∏ (progress –ø–æ–ª—è)
        # LTF progress
        p_ltf_matches = re.findall(self.field_patterns['progress_ltf'], line)
        for suffix, value in p_ltf_matches:
            field_name = f"p{suffix}"
            fields[field_name] = float(value)
            fields[f"{field_name}_type"] = 'LTF_PROGRESS'
        
        # HTF progress 
        p_htf_matches = re.findall(self.field_patterns['progress_htf'], line)
        for suffix, value in p_htf_matches:
            field_name = f"p{suffix}"
            fields[field_name] = float(value)
            fields[f"{field_name}_type"] = 'HTF_PROGRESS'
        
        return fields
    
    def _is_numeric_value(self, value: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã–º (–≤–∫–ª—é—á–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Å --)"""
        # –£–±–∏—Ä–∞–µ–º % –µ—Å–ª–∏ –µ—Å—Ç—å
        clean_value = value.replace('%', '')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        numeric_patterns = [
            r'^-?\d+(?:\.\d+)?$',      # 3.33, -4.12
            r'^--\d+(?:\.\d+)?$',      # --7.19, --4.12
        ]
        
        for pattern in numeric_patterns:
            if re.match(pattern, clean_value):
                return True
        
        return False
    
    def _parse_numeric_value(self, value: str) -> float:
        """–ü–∞—Ä—Å–∏—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        # –£–±–∏—Ä–∞–µ–º % –µ—Å–ª–∏ –µ—Å—Ç—å
        clean_value = value.replace('%', '')
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å –¥–≤–æ–π–Ω—ã–º–∏ –¥–µ—Ñ–∏—Å–∞–º–∏
        if clean_value.startswith('--'):
            # --7.19 ‚Üí -7.19
            return -float(clean_value[2:])
        else:
            # 3.33, -4.12
            return float(clean_value)
    
    def _generate_parsing_statistics(self, df: pd.DataFrame):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π"""
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ó–í–õ–ï–ß–ï–ù–ù–´–• –ü–û–õ–ï–ô:")
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–æ–ª–µ–π –ø–æ –≥—Ä—É–ø–ø–∞–º
        field_groups = {
            'nw_fields': [col for col in df.columns if col.startswith('nw') and not col.endswith('_signal') and not col.endswith('_type')],
            'ef_fields': [col for col in df.columns if col.startswith('ef') and not col.endswith('_type')],
            'as_fields': [col for col in df.columns if col.startswith('as') and not col.endswith('_type')],
            'vc_fields': [col for col in df.columns if col.startswith('vc') and not col.endswith('_type')],
            'ze_fields': [col for col in df.columns if col.startswith('ze') and not col.endswith('_type')],
            'sigma_fields': [col for col in df.columns if any(col.startswith(prefix) for prefix in ['rz', 'mz', 'cz', 'dz', 'cvz', 'maz', 'ciz', 'sz']) and not col.endswith('_type')],
            'momentum_fields': [col for col in df.columns if any(col.startswith(prefix) for prefix in ['co', 'ro', 'mo', 'do', 'so']) and not col.endswith('_type')],
            'metadata_fields': [col for col in df.columns if col in ['open', 'high', 'low', 'close', 'volume', 'range']]
        }
        
        for group_name, fields in field_groups.items():
            if fields:
                print(f"   {group_name}: {len(fields)} –ø–æ–ª–µ–π")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π
                if group_name in ['nw_fields', 'ef_fields', 'as_fields', 'vc_fields', 'ze_fields']:
                    for field in fields[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –ø–æ–ª—è
                        non_null = df[field].dropna()
                        if len(non_null) > 0:
                            print(f"      {field}: –º–∏–Ω={non_null.min():.2f}, –º–∞–∫—Å={non_null.max():.2f}, –∞–∫—Ç–∏–≤–∞—Ü–∏–π={len(non_null)}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π
        critical_fields = ['nw2', 'ef2', 'as2', 'vc2', 'ze2']
        print(f"\nüéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–û–õ–Ø:")
        for field in critical_fields:
            if field in df.columns:
                non_null_count = df[field].notna().sum()
                if non_null_count > 0:
                    sample_values = df[field].dropna().head(3).tolist()
                    print(f"   ‚úÖ {field}: –Ω–∞–π–¥–µ–Ω–æ {non_null_count} –∞–∫—Ç–∏–≤–∞—Ü–∏–π, –ø—Ä–∏–º–µ—Ä—ã: {sample_values}")
                else:
                    print(f"   ‚ö†Ô∏è {field}: –ø–æ–ª–µ –µ—Å—Ç—å, –Ω–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NULL")
            else:
                print(f"   ‚ùå {field}: –ù–ï –ù–ê–ô–î–ï–ù–û")
    
    def get_ltf_htf_separation(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–ï —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –Ω–∞ LTF –∏ HTF –ø–æ —Ç–∏–ø–∞–º
        
        Returns:
            (ltf_df, htf_df): –æ—Ç–¥–µ–ª—å–Ω—ã–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—ã –¥–ª—è LTF –∏ HTF
        """
        print("‚ö° –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ LTF/HTF –ø–æ —Ç–∏–ø–∞–º –ø–æ–ª–µ–π...")
        
        # –û–±—â–∏–µ –ø–æ–ª—è (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π)
        common_fields = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'range', 
                        'candle_color', 'candle_type', 'line_number', 'raw_line']
        
        ltf_columns = [col for col in common_fields if col in df.columns]
        htf_columns = [col for col in common_fields if col in df.columns]
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –ø–æ —Ç–∏–ø–∞–º
        for col in df.columns:
            if col.endswith('_type'):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è —Ç–∏–ø–æ–≤
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∏–ø–∞ –ø–æ–ª—è
            type_col = f"{col}_type"
            if type_col in df.columns:
                field_types = df[type_col].dropna().unique()
                
                # LTF –ø–æ–ª—è
                if any('LTF' in str(t) for t in field_types):
                    ltf_columns.append(col)
                    if type_col in df.columns:
                        ltf_columns.append(type_col)
                
                # HTF –ø–æ–ª—è  
                if any('HTF' in str(t) for t in field_types):
                    htf_columns.append(col)
                    if type_col in df.columns:
                        htf_columns.append(type_col)
            else:
                # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Å—É—Ñ—Ñ–∏–∫—Å–∞–º
                for suffix in self.ltf_suffixes:
                    if col.endswith(suffix):
                        ltf_columns.append(col)
                        break
                else:
                    for suffix in self.htf_suffixes:
                        if col.endswith(suffix):
                            htf_columns.append(col)
                            break
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤
        ltf_df = df[[col for col in set(ltf_columns) if col in df.columns]].copy()
        htf_df = df[[col for col in set(htf_columns) if col in df.columns]].copy()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        ltf_indicator_fields = [col for col in ltf_df.columns 
                               if not col in common_fields and not col.endswith('_type')]
        htf_indicator_fields = [col for col in htf_df.columns 
                               if not col in common_fields and not col.endswith('_type')]
        
        print(f"   LTF: {len(ltf_indicator_fields)} –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ª–µ–π")
        print(f"   HTF: {len(htf_indicator_fields)} –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ª–µ–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ–ª–µ–π
        if ltf_indicator_fields:
            print(f"   LTF –ø—Ä–∏–º–µ—Ä—ã: {', '.join(ltf_indicator_fields[:5])}")
        if htf_indicator_fields:
            print(f"   HTF –ø—Ä–∏–º–µ—Ä—ã: {', '.join(htf_indicator_fields[:5])}")
        
        return ltf_df, htf_df
    
    def validate_parsing_quality(self, df: pd.DataFrame) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        
        validation_results = {
            'total_records': len(df),
            'total_fields': len(df.columns),
            'critical_fields_found': 0,
            'parsing_quality_score': 0.0,
            'field_coverage': {}
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π
        critical_fields = ['nw2', 'ef2', 'as2', 'vc2', 'ze2']
        for field in critical_fields:
            if field in df.columns and df[field].notna().sum() > 0:
                validation_results['critical_fields_found'] += 1
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
        parsing_quality = validation_results['critical_fields_found'] / len(critical_fields)
        validation_results['parsing_quality_score'] = parsing_quality
        
        if parsing_quality >= 0.8:
            print("   ‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞!")
        elif parsing_quality >= 0.6:
            print("   ‚ö†Ô∏è –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        else:
            print("   ‚ùå –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç—ã")
        
        return validation_results


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_parser_on_sample():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û –ø–∞—Ä—Å–µ—Ä–∞ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –¥–∞–Ω–Ω—ã—Ö"""
    sample_line = """[2024-08-05T09:24:00.000+03:00]: LTF|event_2025-06-28_22-55|1|2024-08-05 06:24|RED|-1.79%|11.5K|BIG_BODY|66%|-18.8%_24h|o:50254.8|h:50258.6|l:48888|c:49353.4|rng:1370.6|p2-0,p5-80,p15-60,p30-80,md5-47%,md15-206.5%,md30-153.3%,cmd5-1.1%,cmd30-11%,macd5-9.1%,ro2-11,ro5-15,ro15-19,ro30-12,mo2-12,mo5-15,mo30-15,co2--213,co5--299,co15--316,co30--153,cz2--0.24,cz5--0.31,cz15--0.2,cz30--0.23,do5-32,do15-31,do30-32,so2-11,so5-9,so15-8,so30-5,rz2--2.63,rz5--2.44,rz15--1.53,rz30--2.3,mz2--2.29,mz30--1.7,ciz2--1.66,ciz5--2.42,ciz15--2.17,sz30--1.58,dz5--2.21,dz15--1.89,dz30--1.83,cvz2--2.55,cvz5--1.71,cvz15--2.36,cvz30--3.41,maz2--4.06,maz15--2.23,maz30--3.7,ef2--7.19,ef5--4.32,ef15--3.72,ef30--5.03,vc2-2.4,vc5-3.3,vc15-3,ze2--4.12,ze5--2.5,ze15--2.71,ze30--4.6,nw2-!!,nw5-!!,nw15-!!,nw30-!!,as2-3.33,as5-4.39,as15-3.56,as30-4.31,vw2--3.09,vw5--3,vw15--2.47"""
    
    parser = AdvancedLogParser()
    record = parser._parse_single_line(sample_line, 0)
    
    print("üß™ –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û –ü–ê–†–°–ï–†–ê:")
    print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ–ª–µ–π: {len(record)}")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π
    critical_fields = [
        ('nw2', '!!'), ('ef2', -7.19), ('as2', 3.33), ('vc2', 2.4), ('ze2', -4.12)
    ]
    
    print("üéØ –ü–†–û–í–ï–†–ö–ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –ü–û–õ–ï–ô:")
    for field_name, expected_value in critical_fields:
        if field_name in record:
            actual_value = record[field_name]
            if actual_value == expected_value:
                print(f"   ‚úÖ {field_name}: {actual_value} (–ü–†–ê–í–ò–õ–¨–ù–û)")
            else:
                print(f"   ‚ö†Ô∏è {field_name}: {actual_value} (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_value})")
        else:
            print(f"   ‚ùå {field_name}: –ù–ï –ù–ê–ô–î–ï–ù–û")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ ef –∏ ze –ø–æ–ª—è
    print(f"\nüî• –í–°–ï EF –ü–û–õ–Ø:")
    for key, value in record.items():
        if key.startswith('ef') and not key.endswith('_type'):
            print(f"   {key}: {value}")
    
    print(f"\nüî• –í–°–ï ZE –ü–û–õ–Ø:")
    for key, value in record.items():
        if key.startswith('ze') and not key.endswith('_type'):
            print(f"   {key}: {value}")


if __name__ == "__main__":
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û –ü–ê–†–°–ï–†–ê")
    print("=" * 50)
    
    test_parser_on_sample()
    
    print("\nüéØ –ì–û–¢–û–í –ö –†–ê–ë–û–¢–ï –° –†–ï–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò!")
