#!/usr/bin/env python3
"""
API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–∫–æ—Ä–∏–Ω–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import json
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class ScoringAPI:
    """
    API –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π —Å–∫–æ—Ä–∏–Ω–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
    """
    
    def __init__(self, config_path="results/scoring_config.json", weights_path="results/weight_matrix.csv"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API
        
        Args:
            config_path: –ø—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞
            weights_path: –ø—É—Ç—å –∫ –º–∞—Ç—Ä–∏—Ü–µ –≤–µ—Å–æ–≤
        """
        self.config = None
        self.weights = None
        self.thresholds = {}
        self.field_weights = {}
        self.is_ready = False
        
        try:
            self.load_configuration(config_path, weights_path)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    
    def load_configuration(self, config_path, weights_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –≤–µ—Å–æ–≤"""
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if Path(config_path).exists():
            with open(config_path, 'r') as f:
                self.config = json.load(f)
            
            self.thresholds = self.config.get('thresholds', {})
            self.field_weights = self.config.get('weights', {})
        else:
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config_path}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –≤–µ—Å–æ–≤
        if Path(weights_path).exists():
            self.weights = pd.read_csv(weights_path)
        else:
            print(f"‚ö†Ô∏è –ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {weights_path}")
        
        self.is_ready = True
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def parse_log_line(self, log_line):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        
        Args:
            log_line: —Å—Ç—Ä–æ–∫–∞ –ª–æ–≥–∞
            
        Returns:
            dict: —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        if not isinstance(log_line, str) or not log_line.strip():
            return {}
        
        data = {}
        
        try:
            # –ë–∞–∑–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥
            if '|' not in log_line:
                return {}
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
            parts = log_line.split('|')
            
            if len(parts) < 6:
                return {}
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            try:
                data['color'] = parts[4] if len(parts) > 4 else 'UNKNOWN'
                data['price_change'] = self._parse_percentage(parts[5]) if len(parts) > 5 else 0
                data['volume'] = self._parse_volume(parts[6]) if len(parts) > 6 else 0
            except (IndexError, ValueError):
                pass
            
            # –ü–æ–∏—Å–∫ OHLC –¥–∞–Ω–Ω—ã—Ö
            remaining_data = '|'.join(parts[6:]) if len(parts) > 6 else ''
            
            ohlc_match = re.search(r'o:([\d.]+).*?h:([\d.]+).*?l:([\d.]+).*?c:([\d.]+)', remaining_data)
            if ohlc_match:
                data['open'] = float(ohlc_match.group(1))
                data['high'] = float(ohlc_match.group(2))
                data['low'] = float(ohlc_match.group(3))
                data['close'] = float(ohlc_match.group(4))
                data['range'] = data['high'] - data['low']
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–ª–µ–π
            import re
            field_pattern = r'([a-zA-Z]+\d*)-?([\d.-]+%?[a-zA-Z]*!*)'
            fields = re.findall(field_pattern, remaining_data)
            
            for field_name, field_value in fields:
                if field_name in ['o', 'h', 'l', 'c', 'rng']:
                    continue
                
                try:
                    # –û—á–∏—Å—Ç–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è
                    clean_value = field_value.replace('%', '').replace('!', '').replace('œÉ', '')
                    if clean_value.replace('.', '').replace('-', '').isdigit():
                        data[field_name] = float(clean_value)
                    else:
                        data[field_name] = field_value
                except ValueError:
                    data[field_name] = field_value
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏: {e}")
        
        return data
    
    def _parse_percentage(self, value_str):
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            if '%' in value_str:
                return float(value_str.replace('%', ''))
            return float(value_str)
        except ValueError:
            return 0.0
    
    def _parse_volume(self, volume_str):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            volume_str = volume_str.upper()
            if 'K' in volume_str:
                return float(volume_str.replace('K', '')) * 1000
            elif 'M' in volume_str:
                return float(volume_str.replace('M', '')) * 1000000
            return float(volume_str)
        except ValueError:
            return 0.0
    
    def calculate_score(self, data_dict):
        """
        –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            data_dict: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª–µ–π
            
        Returns:
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞
        """
        if not self.is_ready:
            return {'error': 'API –Ω–µ –≥–æ—Ç–æ–≤', 'score': 0, 'confidence': 0}
        
        try:
            score = 0.0
            active_features = 0
            feature_contributions = {}
            
            # –ü—Ä–æ—Ö–æ–¥ –ø–æ –≤—Å–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –ø–æ–ª—è–º
            for field_name, threshold in self.thresholds.items():
                if field_name in data_dict:
                    field_value = data_dict[field_name]
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ–ª—è
                    if isinstance(field_value, (int, float)) and abs(field_value) > threshold:
                        # –ü–æ–ª–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ
                        feature_key = f"{field_name}_activated"
                        weight = self.field_weights.get(feature_key, 0)
                        
                        if weight > 0:
                            contribution = weight * min(abs(field_value) / threshold, 3.0)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è
                            score += contribution
                            active_features += 1
                            feature_contributions[field_name] = {
                                'value': field_value,
                                'threshold': threshold,
                                'weight': weight,
                                'contribution': contribution
                            }
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–∞
            if active_features > 0:
                normalized_score = min(score / active_features, 1.0)
                confidence = min(active_features / 5.0, 1.0)  # –ë–æ–ª—å—à–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª–µ–π = –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            else:
                normalized_score = 0.0
                confidence = 0.0
            
            return {
                'score': normalized_score,
                'confidence': confidence,
                'active_features': active_features,
                'feature_contributions': feature_contributions,
                'raw_score': score
            }
            
        except Exception as e:
            return {'error': str(e), 'score': 0, 'confidence': 0}
    
    def score_log_line(self, log_line):
        """
        –°–∫–æ—Ä–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞
        
        Args:
            log_line: —Å—Ç—Ä–æ–∫–∞ –ª–æ–≥–∞
            
        Returns:
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞
        """
        # –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏
        data = self.parse_log_line(log_line)
        
        if not data:
            return {'error': '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É', 'score': 0, 'confidence': 0}
        
        # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞
        result = self.calculate_score(data)
        result['timestamp'] = datetime.now().isoformat()
        result['parsed_fields'] = len(data)
        
        return result
    
    def score_multiple_lines(self, log_lines):
        """
        –°–∫–æ—Ä–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–æ–∫ –ª–æ–≥–∞
        
        Args:
            log_lines: —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –ª–æ–≥–∞
            
        Returns:
            list: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–æ—Ä–∏–Ω–≥–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        """
        results = []
        
        for i, line in enumerate(log_lines):
            result = self.score_log_line(line)
            result['line_number'] = i + 1
            results.append(result)
        
        return results
    
    def score_file(self, file_path, output_path=None):
        """
        –°–∫–æ—Ä–∏–Ω–≥ —Ñ–∞–π–ª–∞ –ª–æ–≥–∞
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞
            output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            dict: —Å–≤–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        print(f"üìä –°–∫–æ—Ä–∏–Ω–≥ —Ñ–∞–π–ª–∞: {file_path}")
        
        if not Path(file_path).exists():
            return {'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}
        
        results = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                result = self.score_log_line(line)
                result['line_number'] = line_num
                results.append(result)
        
        # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        valid_results = [r for r in results if 'error' not in r]
        
        if valid_results:
            scores = [r['score'] for r in valid_results]
            confidences = [r['confidence'] for r in valid_results]
            
            summary = {
                'total_lines': len(results),
                'valid_lines': len(valid_results),
                'avg_score': np.mean(scores),
                'max_score': np.max(scores),
                'min_score': np.min(scores),
                'avg_confidence': np.mean(confidences),
                'high_score_lines': len([s for s in scores if s > 0.7]),
                'low_score_lines': len([s for s in scores if s < 0.3])
            }
        else:
            summary = {'error': '–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'}
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if output_path:
            output_data = {
                'summary': summary,
                'line_results': results,
                'generation_time': datetime.now().isoformat(),
                'config_used': self.config
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
        
        print(f"‚úÖ –°–∫–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä: {summary.get('avg_score', 0):.3f}")
        
        return {'summary': summary, 'results': results}
    
    def get_top_scoring_lines(self, results, top_n=10):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º–∏ —Å–∫–æ—Ä–∞–º–∏
        
        Args:
            results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–æ—Ä–∏–Ω–≥–∞
            top_n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Å—Ç—Ä–æ–∫
            
        Returns:
            list: —Ç–æ–ø —Å—Ç—Ä–æ–∫–∏ —Å –¥–µ—Ç–∞–ª—è–º–∏
        """
        valid_results = [r for r in results if 'error' not in r and r['score'] > 0]
        top_results = sorted(valid_results, key=lambda x: x['score'], reverse=True)[:top_n]
        
        return top_results
    
    def get_feature_statistics(self, results):
        """
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ–ª–µ–π
        
        Args:
            results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–æ—Ä–∏–Ω–≥–∞
            
        Returns:
            dict: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª–µ–π
        """
        field_stats = {}
        
        for result in results:
            if 'feature_contributions' in result:
                for field_name, details in result['feature_contributions'].items():
                    if field_name not in field_stats:
                        field_stats[field_name] = {
                            'activation_count': 0,
                            'total_contribution': 0,
                            'avg_value': 0,
                            'max_value': 0,
                            'values': []
                        }
                    
                    stats = field_stats[field_name]
                    stats['activation_count'] += 1
                    stats['total_contribution'] += details['contribution']
                    stats['values'].append(details['value'])
                    stats['max_value'] = max(stats['max_value'], abs(details['value']))
        
        # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for field_name, stats in field_stats.items():
            if stats['values']:
                stats['avg_value'] = np.mean(stats['values'])
                stats['std_value'] = np.std(stats['values'])
                stats['avg_contribution'] = stats['total_contribution'] / stats['activation_count']
        
        return field_stats
    
    def create_monitoring_dashboard_data(self, file_path, window_size=50):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è dashboard –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        
        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞
            window_size: —Ä–∞–∑–º–µ—Ä —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞
            
        Returns:
            dict: –¥–∞–Ω–Ω—ã–µ –¥–ª—è dashboard
        """
        results = self.score_file(file_path)
        
        if 'error' in results:
            return results
        
        line_results = results['results']
        valid_results = [r for r in line_results if 'error' not in r]
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        scores = [r['score'] for r in valid_results]
        rolling_avg = []
        
        for i in range(len(scores)):
            start_idx = max(0, i - window_size + 1)
            window_scores = scores[start_idx:i+1]
            rolling_avg.append(np.mean(window_scores))
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (—Å–∫–æ—Ä > 0.8)
        anomalies = [
            {'line': r['line_number'], 'score': r['score'], 'confidence': r['confidence']}
            for r in valid_results if r['score'] > 0.8
        ]
        
        dashboard_data = {
            'timeline': {
                'scores': scores,
                'rolling_average': rolling_avg,
                'line_numbers': [r['line_number'] for r in valid_results]
            },
            'anomalies': anomalies,
            'statistics': results['summary'],
            'field_activity': self.get_feature_statistics(valid_results),
            'alert_level': 'HIGH' if len(anomalies) > 5 else 'MEDIUM' if len(anomalies) > 0 else 'LOW'
        }
        
        return dashboard_data


class RealTimeScoringAPI(ScoringAPI):
    """
    API –¥–ª—è —Å–∫–æ—Ä–∏–Ω–≥–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.recent_scores = []
        self.alert_threshold = 0.8
        self.max_history = 1000
    
    def process_realtime_line(self, log_line):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        
        Args:
            log_line: –Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ª–æ–≥–∞
            
        Returns:
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        result = self.score_log_line(log_line)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.recent_scores.append(result)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.recent_scores) > self.max_history:
            self.recent_scores = self.recent_scores[-self.max_history:]
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        recent_scores = [r['score'] for r in self.recent_scores[-10:] if 'error' not in r]
        
        if len(recent_scores) >= 3:
            trend = 'RISING' if recent_scores[-1] > recent_scores[-3] else 'FALLING'
            avg_recent = np.mean(recent_scores[-5:])
        else:
            trend = 'STABLE'
            avg_recent = result['score']
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤
        alerts = []
        
        if result['score'] > self.alert_threshold:
            alerts.append({
                'type': 'HIGH_SCORE',
                'message': f"–í—ã—Å–æ–∫–∏–π —Å–∫–æ—Ä: {result['score']:.3f}",
                'severity': 'HIGH'
            })
        
        if trend == 'RISING' and avg_recent > 0.6:
            alerts.append({
                'type': 'RISING_TREND',
                'message': f"–í–æ–∑—Ä–∞—Å—Ç–∞—é—â–∏–π —Ç—Ä–µ–Ω–¥: {avg_recent:.3f}",
                'severity': 'MEDIUM'
            })
        
        # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result.update({
            'trend': trend,
            'recent_average': avg_recent,
            'alerts': alerts,
            'history_size': len(self.recent_scores)
        })
        
        return result
    
    def get_current_statistics(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if not self.recent_scores:
            return {'message': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}
        
        valid_scores = [r['score'] for r in self.recent_scores if 'error' not in r]
        
        if not valid_scores:
            return {'message': '–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–∫–æ—Ä–æ–≤'}
        
        return {
            'total_processed': len(self.recent_scores),
            'avg_score': np.mean(valid_scores),
            'max_score': np.max(valid_scores),
            'recent_avg': np.mean(valid_scores[-10:]) if len(valid_scores) >= 10 else np.mean(valid_scores),
            'alert_count': len([r for r in self.recent_scores if r.get('alerts', [])]),
            'last_update': datetime.now().isoformat()
        }


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API"""
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Scoring API")
    print("=" * 40)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ API
    api = ScoringAPI()
    
    if not api.is_ready:
        print("‚ùå API –Ω–µ –≥–æ—Ç–æ–≤. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.")
        return
    
    # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞
    sample_line = """[2024-08-05T09:30:00.000+03:00]: LTF|event_test|1|2024-08-05 06:30|GREEN|0.91%|2.1K|NORMAL|97%|-16.92%_24h|o:50010|h:50475.5|l:50004|c:50465.5|rng:471.5|p2-0,p5-0,p15-0,p30-0,rd5-12.3%,mo15-85,cvz2--2.1"""
    
    print("üìù –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–∞:")
    print(sample_line[:100] + "...")
    print()
    
    # –°–∫–æ—Ä–∏–Ω–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    result = api.score_log_line(sample_line)
    
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞:")
    print(f"   –°–∫–æ—Ä: {result.get('score', 0):.3f}")
    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.get('confidence', 0):.3f}")
    print(f"   –ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª–µ–π: {result.get('active_features', 0)}")
    
    if 'feature_contributions' in result:
        print("   –í–∫–ª–∞–¥ –ø–æ–ª–µ–π:")
        for field, contrib in list(result['feature_contributions'].items())[:3]:
            print(f"     {field}: {contrib['contribution']:.3f}")
    
    print()
    print("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


if __name__ == "__main__":
    main()