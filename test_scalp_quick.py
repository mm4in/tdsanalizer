#!/usr/bin/env python3
"""
–ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ö–ê–õ–¨–ü –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê - –ü–†–û–í–ï–†–Ø–ï–ú –í–°–Æ –°–ò–°–¢–ï–ú–£
"""

import sys
import os
import pandas as pd
import numpy as np

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥—É–ª—è–º–∏
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from scalp_analyzer import ScalpAnalyzer
    print("‚úÖ –ò–ú–ü–û–†–¢ –°–ö–ê–õ–¨–ü –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê –£–°–ü–ï–®–ï–ù")
except ImportError as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê –°–ö–ê–õ–¨–ü –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê: {e}")
    
    try:
        from advanced_log_parser import AdvancedLogParser
        print("‚úÖ –ò–ú–ü–û–†–¢ –ü–ê–†–°–ï–†–ê –£–°–ü–ï–®–ï–ù")
        print("‚ö†Ô∏è –ë—É–¥–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–µ—Ä")
        USE_FULL_ANALYZER = False
    except ImportError as e2:
        print(f"‚ùå –û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê –ü–ê–†–°–ï–†–ê: {e2}")
        sys.exit(1)
else:
    USE_FULL_ANALYZER = True

def test_full_scalp_analyzer():
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞–ª—å–ø –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    log_file = "data/dslog_btc_0508240229_ltf.txt"
    
    if not os.path.exists(log_file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_file}")
        return False
    
    print(f"\nüöÄ –¢–ï–°–¢ –ü–û–õ–ù–û–ì–û –°–ö–ê–õ–¨–ü –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
    print("=" * 50)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = ScalpAnalyzer()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        analyzer.analyze_log(log_file)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if analyzer.df is None or analyzer.df.empty:
            print("‚ùå –î–ê–ù–ù–´–ï –ù–ï –ó–ê–ì–†–£–ñ–ï–ù–´")
            return False
        
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(analyzer.df)} –∑–∞–ø–∏—Å–µ–π, {len(analyzer.df.columns)} –ø–æ–ª–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏—è
        if not analyzer.events:
            print("‚ùå –°–û–ë–´–¢–ò–Ø –ù–ï –ù–ê–ô–î–ï–ù–´") 
            return False
        
        print(f"‚úÖ –°–æ–±—ã—Ç–∏—è –Ω–∞–π–¥–µ–Ω—ã: {len(analyzer.events)}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å–æ–±—ã—Ç–∏–π
        event_types = {}
        for event in analyzer.events:
            event_type = event['type']
            event_types[event_type] = event_types.get(event_type, 0) + 1
        
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–û–ë–´–¢–ò–ô:")
        for event_type, count in event_types.items():
            print(f"   {event_type}: {count}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if hasattr(analyzer, 'pattern_stats') and analyzer.pattern_stats:
            print(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        else:
            print(f"‚ùå –ü–ê–¢–¢–ï–†–ù–´ –ù–ï –ü–†–û–ê–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–´")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–ª—Å—è –ª–∏ –æ—Ç—á–µ—Ç
        report_file = "scalp_analysis_report.txt"
        if os.path.exists(report_file):
            print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_file}")
        else:
            print(f"‚ùå –û–¢–ß–ï–¢ –ù–ï –°–û–ó–î–ê–ù")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê –ü–†–ò –ê–ù–ê–õ–ò–ó–ï: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_parser_only():
    """–¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–µ—Ä–∞ (–µ—Å–ª–∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)"""
    
    log_file = "data/dslog_btc_0508240229_ltf.txt"
    
    if not os.path.exists(log_file):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {log_file}")
        return False
    
    print(f"\nüìä –¢–ï–°–¢ –¢–û–õ–¨–ö–û –ü–ê–†–°–ï–†–ê")
    print("=" * 30)
    
    from advanced_log_parser import AdvancedLogParser
    
    parser = AdvancedLogParser()
    df = parser.parse_log_file(log_file)
    
    if df.empty:
        print("‚ùå –ü–ê–†–°–ï–† –ù–ï –†–ê–ë–û–¢–ê–ï–¢")
        return False
    
    print(f"‚úÖ –ü–∞—Ä—Å–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç: {len(df)} –∑–∞–ø–∏—Å–µ–π, {len(df.columns)} –ø–æ–ª–µ–π")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è
    critical_fields = ['ef2', 'as2', 'vc2', 'nw2', 'ze2']
    found_critical = []
    
    for field in critical_fields:
        if field in df.columns:
            non_null_count = df[field].notna().sum()
            if non_null_count > 0:
                found_critical.append(field)
                print(f"   ‚úÖ {field}: {non_null_count} –∞–∫—Ç–∏–≤–∞—Ü–∏–π")
            else:
                print(f"   ‚ö†Ô∏è {field}: –ø–æ–ª–µ –µ—Å—Ç—å, –Ω–æ –≤—Å–µ NULL")
        else:
            print(f"   ‚ùå {field}: –ù–ï –ù–ê–ô–î–ï–ù–û")
    
    print(f"\n–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π –Ω–∞–π–¥–µ–Ω–æ: {len(found_critical)}/{len(critical_fields)}")
    
    return len(found_critical) >= 3

def simple_event_detection(df):
    """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —Å–æ–±—ã—Ç–∏–π –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"""
    
    if 'low' not in df.columns or 'high' not in df.columns:
        print("‚ùå –ù–ï–¢ –î–ê–ù–ù–´–• –û –¶–ï–ù–ê–•")
        return []
    
    print(f"\nüîç –ü–†–û–°–¢–û–ô –ü–û–ò–°–ö –°–û–ë–´–¢–ò–ô")
    print("=" * 30)
    
    events = []
    window = 5  # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ
    
    # –ò—â–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã
    for i in range(window, len(df) - window):
        current_low = df.iloc[i]['low']
        is_local_min = True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–∏–Ω–∏–º—É–º–æ–º
        for j in range(i - window, i + window + 1):
            if j != i and df.iloc[j]['low'] <= current_low:
                is_local_min = False
                break
        
        if is_local_min:
            # –ò—â–µ–º –æ—Ç–∫–∞—Ç –≤ —Å–ª–µ–¥—É—é—â–∏—Ö 10 —Å–≤–µ—á–∞—Ö
            future_slice = df.iloc[i:i+10]
            if len(future_slice) > 5:
                max_high = future_slice['high'].max()
                rebound_pct = ((max_high - current_low) / current_low) * 100
                
                if rebound_pct >= 3.0:
                    events.append({
                        'type': '–õ–û–ô_–ö–û–ù–¢–†–¢–†–ï–ù–î',
                        'rebound_pct': rebound_pct,
                        'index': i
                    })
                elif rebound_pct < 1.0:
                    events.append({
                        'type': '–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï_–î–ê–ú–ü–ê', 
                        'rebound_pct': rebound_pct,
                        'index': i
                    })
    
    print(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {len(events)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    event_counts = {}
    for event in events:
        event_type = event['type']
        event_counts[event_type] = event_counts.get(event_type, 0) + 1
    
    for event_type, count in event_counts.items():
        print(f"   {event_type}: {count}")
    
    return events

if __name__ == "__main__":
    print("üöÄ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –°–ö–ê–õ–¨–ü –°–ò–°–¢–ï–ú–´")
    print("=" * 60)
    
    if USE_FULL_ANALYZER:
        # –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        full_test_passed = test_full_scalp_analyzer()
        
        if full_test_passed:
            print(f"\nüéâ –°–ö–ê–õ–¨–ü –ê–ù–ê–õ–ò–ó–ê–¢–û–† –†–ê–ë–û–¢–ê–ï–¢ –ü–û–õ–ù–û–°–¢–¨–Æ!")
        else:
            print(f"\n‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´ –° –ü–û–õ–ù–´–ú –ê–ù–ê–õ–ò–ó–ê–¢–û–†–û–ú, –¢–ï–°–¢–ò–†–£–ï–ú –ü–ê–†–°–ï–†...")
            parser_test_passed = test_parser_only()
            
            if parser_test_passed:
                print(f"\n‚úÖ –ü–ê–†–°–ï–† –†–ê–ë–û–¢–ê–ï–¢, –ü–†–û–ë–õ–ï–ú–ê –í –õ–û–ì–ò–ö–ï –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê")
            else:
                print(f"\n‚ùå –ü–ê–†–°–ï–† –ù–ï –†–ê–ë–û–¢–ê–ï–¢ - –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê")
    else:
        # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–µ—Ä–∞
        parser_test_passed = test_parser_only()
        
        if parser_test_passed:
            print(f"\n‚úÖ –ü–ê–†–°–ï–† –†–ê–ë–û–¢–ê–ï–¢")
            
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —Å–æ–±—ã—Ç–∏–π
            from advanced_log_parser import AdvancedLogParser
            parser = AdvancedLogParser() 
            df = parser.parse_log_file("data/dslog_btc_0508240229_ltf.txt")
            events = simple_event_detection(df)
            
            if events:
                print(f"‚úÖ –ü–†–û–°–¢–û–ô –ü–û–ò–°–ö –°–û–ë–´–¢–ò–ô –†–ê–ë–û–¢–ê–ï–¢")
            else:
                print(f"‚ùå –°–û–ë–´–¢–ò–Ø –ù–ï –ù–ê–ô–î–ï–ù–´")
        else:
            print(f"\n‚ùå –ü–ê–†–°–ï–† –ù–ï –†–ê–ë–û–¢–ê–ï–¢")
    
    print(f"\nüìã –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:")
    if USE_FULL_ANALYZER and 'full_test_passed' in locals() and full_test_passed:
        print(f"   üéØ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
        print(f"   üìä –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª scalp_analysis_report.txt")
    elif 'parser_test_passed' in locals() and parser_test_passed:
        print(f"   üîß –ü–∞—Ä—Å–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –Ω—É–∂–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥–∏–∫–∏")
        print(f"   üìä –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ")
    else:
        print(f"   üö® –°–ò–°–¢–ï–ú–ê –ù–ï –†–ê–ë–û–¢–ê–ï–¢ - –¢–†–ï–ë–£–ï–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
