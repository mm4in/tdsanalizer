#!/usr/bin/env python3
"""
–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥ LTF + HTF
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±—ã—Å—Ç—Ä—ã—Ö –∏ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤

–°–æ–∑–¥–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞:
1. LTF —Å–∫–æ—Ä–∏–Ω–≥ –¥–ª—è –º–∏–∫—Ä–æ—Å–∫–∞–ª—å–ø–∏–Ω–≥–∞
2. HTF —Å–∫–æ—Ä–∏–Ω–≥ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞  
3. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import yaml
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler


class CombinedScorer:
    """
    –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥ LTF + HTF
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:
    1. Weighted Ensemble - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    2. Sequential Logic - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
    3. Adaptive Weights - –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –ø–æ —Å–∏—Ç—É–∞—Ü–∏–∏
    4. Hierarchical Decision - –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π
    """
    
    def __init__(self, config_path="config.yaml"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–æ—Ä–µ—Ä–∞"""
        self.config = self._load_config(config_path)
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.ltf_results = None
        self.htf_results = None
        self.veto_rules = None
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.combined_models = {}
        self.scoring_scenarios = {}
        self.adaptive_weights = {}
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.combination_analysis = {}
        self.scenario_validation = {}
        self.final_recommendations = {}
        
    def _load_config(self, config_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        default_config = {
            'combined_scoring': {
                'ensemble_methods': ['weighted', 'voting', 'stacking'],
                'adaptive_weighting': True,
                'scenario_based': True,
                'confidence_thresholds': [0.3, 0.5, 0.7, 0.9],
                'combination_strategies': [
                    'ltf_primary', 'htf_primary', 'balanced', 
                    'adaptive', 'hierarchical'
                ]
            }
        }
        
        if Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
                if user_config:
                    default_config.update(user_config)
        
        return default_config
    
    def create_combined_scoring_system(self, ltf_results, htf_results, veto_rules=None):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Å–∫–æ—Ä–∏–Ω–≥–∞
        
        Args:
            ltf_results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã LTF –∞–Ω–∞–ª–∏–∑–∞
            htf_results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã HTF –∞–Ω–∞–ª–∏–∑–∞
            veto_rules: –ø—Ä–∞–≤–∏–ª–∞ VETO —Å–∏—Å—Ç–µ–º—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        print("üîó –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Å–∫–æ—Ä–∏–Ω–≥–∞...")
        
        self.ltf_results = ltf_results
        self.htf_results = htf_results
        self.veto_rules = veto_rules
        
        # –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ LTF –∏ HTF
        self._analyze_ltf_htf_compatibility()
        
        # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞
        self._create_scoring_scenarios()
        
        # –≠—Ç–∞–ø 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        self._build_ensemble_models()
        
        # –≠—Ç–∞–ø 4: –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ
        self._develop_adaptive_weighting()
        
        # –≠—Ç–∞–ø 5: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        self._validate_all_scenarios()
        
        # –≠—Ç–∞–ø 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        self._generate_final_recommendations()
        
        print("‚úÖ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–∫–æ—Ä–∏–Ω–≥–∞ —Å–æ–∑–¥–∞–Ω–∞")
        return self.final_recommendations
    
    def _analyze_ltf_htf_compatibility(self):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ LTF –∏ HTF —Å–∏—Å—Ç–µ–º"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ LTF –∏ HTF...")
        
        compatibility_analysis = {}
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        ltf_performance = self.ltf_results.get('validation', {})
        htf_performance = self.htf_results.get('validation', {})
        
        ltf_roc = ltf_performance.get('roc_auc', 0)
        htf_roc = htf_performance.get('roc_auc', 0)
        
        compatibility_analysis['performance_comparison'] = {
            'ltf_roc_auc': ltf_roc,
            'htf_roc_auc': htf_roc,
            'performance_gap': abs(ltf_roc - htf_roc),
            'better_performer': 'LTF' if ltf_roc > htf_roc else 'HTF',
            'performance_ratio': max(ltf_roc, htf_roc) / (min(ltf_roc, htf_roc) + 0.001)
        }
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ª–∞–≥–æ–≤
        ltf_lags = self.ltf_results.get('temporal_lags', {})
        htf_lags = self.htf_results.get('temporal_lags', {})
        
        lag_correlation = self._calculate_lag_correlation(ltf_lags, htf_lags)
        compatibility_analysis['temporal_correlation'] = lag_correlation
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π
        event_overlap = self._analyze_event_overlap()
        compatibility_analysis['event_overlap'] = event_overlap
        
        # –û—Ü–µ–Ω–∫–∞ —Å–∏–Ω–µ—Ä–≥–∏–∏
        synergy_potential = self._assess_synergy_potential()
        compatibility_analysis['synergy_potential'] = synergy_potential
        
        self.combination_analysis['compatibility'] = compatibility_analysis
        
        print(f"   LTF –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {ltf_roc:.3f}")
        print(f"   HTF –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {htf_roc:.3f}")
        print(f"   –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Å–∏–Ω–µ—Ä–≥–∏–∏: {synergy_potential:.3f}")
    
    def _calculate_lag_correlation(self, ltf_lags, htf_lags):
        """–†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ª–∞–≥–æ–≤"""
        
        # –û–±—â–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ–ª–µ–π
        common_groups = set(ltf_lags.keys()) & set(htf_lags.keys())
        
        if not common_groups:
            return {'correlation': 0, 'common_groups': 0}
        
        ltf_lag_values = [ltf_lags[group]['mean_lag'] for group in common_groups]
        htf_lag_values = [htf_lags[group]['mean_lag'] for group in common_groups]
        
        if len(ltf_lag_values) > 1:
            correlation = np.corrcoef(ltf_lag_values, htf_lag_values)[0, 1]
            if np.isnan(correlation):
                correlation = 0
        else:
            correlation = 0
        
        return {
            'correlation': correlation,
            'common_groups': len(common_groups),
            'ltf_avg_lag': np.mean(ltf_lag_values) if ltf_lag_values else 0,
            'htf_avg_lag': np.mean(htf_lag_values) if htf_lag_values else 0
        }
    
    def _analyze_event_overlap(self):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –º–µ–∂–¥—É LTF –∏ HTF"""
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞: –ø—Ä–æ—Ü–µ–Ω—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        
        ltf_event_rate = self.ltf_results.get('events_rate', 0)
        htf_event_rate = self.htf_results.get('events_rate', 0)
        
        # –≠–º—É–ª—è—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞
        estimated_overlap = min(ltf_event_rate, htf_event_rate) / max(ltf_event_rate, htf_event_rate, 0.001)
        
        return {
            'ltf_event_rate': ltf_event_rate,
            'htf_event_rate': htf_event_rate,
            'estimated_overlap': estimated_overlap,
            'complementarity': 1 - estimated_overlap  # –í–∑–∞–∏–º–æ–¥–æ–ø–æ–ª–Ω—è–µ–º–æ—Å—Ç—å
        }
    
    def _assess_synergy_potential(self):
        """–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Å–∏–Ω–µ—Ä–≥–∏–∏ –º–µ–∂–¥—É LTF –∏ HTF"""
        
        # –§–∞–∫—Ç–æ—Ä—ã —Å–∏–Ω–µ—Ä–≥–∏–∏
        ltf_roc = self.ltf_results.get('validation', {}).get('roc_auc', 0)
        htf_roc = self.htf_results.get('validation', {}).get('roc_auc', 0)
        
        # –ë–∞–∑–æ–≤–∞—è —Å–∏–Ω–µ—Ä–≥–∏—è –æ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_synergy = (ltf_roc + htf_roc) / 2
        
        # –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ (–µ—Å–ª–∏ —Å–∏—Å—Ç–µ–º—ã –¥–æ–ø–æ–ª–Ω—è—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞)
        diversity_bonus = 0
        if abs(ltf_roc - htf_roc) < 0.1:  # –°—Ö–æ–¥–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            diversity_bonus = 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±–µ–∏—Ö —Å–∏—Å—Ç–µ–º
        quality_bonus = 0
        if ltf_roc > 0.6 and htf_roc > 0.6:  # –û–±–µ —Å–∏—Å—Ç–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ
            quality_bonus = 0.15
        
        total_synergy = performance_synergy + diversity_bonus + quality_bonus
        
        return min(1.0, total_synergy)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º–æ–º 1.0
    
    def _create_scoring_scenarios(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞"""
        print("üé≠ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞...")
        
        self.scoring_scenarios = {}
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 1: LTF Primary (–±—ã—Å—Ç—Ä—ã–µ —Å–∏–≥–Ω–∞–ª—ã –≥–ª–∞–≤–Ω—ã–µ)
        self.scoring_scenarios['ltf_primary'] = {
            'description': 'LTF —Å–∏–≥–Ω–∞–ª—ã –æ—Å–Ω–æ–≤–Ω—ã–µ, HTF –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è',
            'ltf_weight': 0.8,
            'htf_weight': 0.2,
            'logic': 'LTF signal * 0.8 + HTF confirmation * 0.2',
            'use_case': '–ú–∏–∫—Ä–æ—Å–∫–∞–ª—å–ø–∏–Ω–≥, –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è'
        }
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 2: HTF Primary (–º–µ–¥–ª–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –≥–ª–∞–≤–Ω—ã–µ)
        self.scoring_scenarios['htf_primary'] = {
            'description': 'HTF –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, LTF –¥–ª—è –≤—Ö–æ–¥–∞',
            'ltf_weight': 0.3,
            'htf_weight': 0.7,
            'logic': 'HTF direction * 0.7 + LTF entry * 0.3',
            'use_case': '–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è, –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏'
        }
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 3: Balanced (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        self.scoring_scenarios['balanced'] = {
            'description': '–†–∞–≤–Ω–æ–≤–µ—Å–∏–µ –º–µ–∂–¥—É LTF –∏ HTF',
            'ltf_weight': 0.5,
            'htf_weight': 0.5,
            'logic': 'LTF signal * 0.5 + HTF signal * 0.5',
            'use_case': '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è'
        }
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 4: Adaptive (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π)
        self.scoring_scenarios['adaptive'] = {
            'description': '–í–µ—Å–∞ –º–µ–Ω—è—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å–ª–æ–≤–∏–π',
            'ltf_weight': 'dynamic',
            'htf_weight': 'dynamic',
            'logic': 'Weights based on market conditions and confidence',
            'use_case': '–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è –ø–æ–¥ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è'
        }
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 5: Hierarchical (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π)
        self.scoring_scenarios['hierarchical'] = {
            'description': 'HTF –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–∂–∏–º, LTF –¥–µ–π—Å—Ç–≤—É–µ—Ç –≤–Ω—É—Ç—Ä–∏ —Ä–µ–∂–∏–º–∞',
            'ltf_weight': 'conditional',
            'htf_weight': 'gate_keeper',
            'logic': 'IF HTF allows THEN LTF signal ELSE 0',
            'use_case': '–°—Ç—Ä–æ–≥–∞—è –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ –≤—Ö–æ–¥–æ–≤'
        }
        
        # –°—Ü–µ–Ω–∞—Ä–∏–π 6: Contrarian (–∫–æ–Ω—Ç—Ä—Ç—Ä–µ–Ω–¥–æ–≤—ã–π)
        self.scoring_scenarios['contrarian'] = {
            'description': 'HTF –ø–µ—Ä–µ–≥—Ä–µ–≤ + LTF —Ä–∞–∑–≤–æ—Ä–æ—Ç',
            'ltf_weight': 0.6,
            'htf_weight': 0.4,
            'logic': 'LTF reversal * 0.6 + HTF exhaustion * 0.4',
            'use_case': '–¢–æ—Ä–≥–æ–≤–ª—è —Ä–∞–∑–≤–æ—Ä–æ—Ç–æ–≤, –∫–æ–Ω—Ç—Ä—Ç—Ä–µ–Ω–¥'
        }
        
        print(f"   –°–æ–∑–¥–∞–Ω–æ {len(self.scoring_scenarios)} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞")
    
    def _build_ensemble_models(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        print("ü§ñ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        
        self.combined_models = {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        if not self._has_sufficient_data():
            print("   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª–µ–π")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_ltf, X_htf, y = self._prepare_ensemble_data()
        
        # –ú–æ–¥–µ–ª—å 1: Weighted Ensemble
        self.combined_models['weighted_ensemble'] = self._build_weighted_ensemble(X_ltf, X_htf, y)
        
        # –ú–æ–¥–µ–ª—å 2: Voting Classifier
        self.combined_models['voting_classifier'] = self._build_voting_classifier(X_ltf, X_htf, y)
        
        # –ú–æ–¥–µ–ª—å 3: Stacked Model
        self.combined_models['stacked_model'] = self._build_stacked_model(X_ltf, X_htf, y)
        
        # –ú–æ–¥–µ–ª—å 4: Meta-Learner
        self.combined_models['meta_learner'] = self._build_meta_learner(X_ltf, X_htf, y)
        
        print(f"   –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ {len(self.combined_models)} –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π")
    
    def _has_sufficient_data(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        
        ltf_features = self.ltf_results.get('features')
        htf_features = self.htf_results.get('features')
        
        if ltf_features is None or htf_features is None:
            return False
        
        if isinstance(ltf_features, pd.DataFrame) and isinstance(htf_features, pd.DataFrame):
            return len(ltf_features) > 50 and len(htf_features) > 50
        
        return False
    
    def _prepare_ensemble_data(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π"""
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        ltf_features = self.ltf_results.get('features')
        htf_features = self.htf_results.get('features')
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º
        common_index = ltf_features.index.intersection(htf_features.index)
        
        X_ltf = ltf_features.loc[common_index].fillna(0)
        X_htf = htf_features.loc[common_index].fillna(0)
        
        # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∏–∑ LTF —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–æ–±—ã—Ç–∏–π)
        y = pd.Series(0, index=common_index)
        if 'is_event' in ltf_features.columns:
            y = ltf_features.loc[common_index, 'is_event'].fillna(0)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if len(X_ltf.columns) > 30:
            X_ltf = X_ltf.iloc[:, :30]
        if len(X_htf.columns) > 30:
            X_htf = X_htf.iloc[:, :30]
        
        return X_ltf, X_htf, y
    
    def _build_weighted_ensemble(self, X_ltf, X_htf, y):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è"""
        
        try:
            # –ü—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö
            ltf_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)
            htf_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            ltf_model.fit(X_ltf, y)
            htf_model.fit(X_htf, y)
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤
            ltf_score = cross_val_score(ltf_model, X_ltf, y, cv=3, scoring='roc_auc').mean()
            htf_score = cross_val_score(htf_model, X_htf, y, cv=3, scoring='roc_auc').mean()
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            total_score = ltf_score + htf_score
            ltf_weight = ltf_score / total_score if total_score > 0 else 0.5
            htf_weight = htf_score / total_score if total_score > 0 else 0.5
            
            return {
                'ltf_model': ltf_model,
                'htf_model': htf_model,
                'ltf_weight': ltf_weight,
                'htf_weight': htf_weight,
                'ltf_score': ltf_score,
                'htf_score': htf_score
            }
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è weighted ensemble: {e}")
            return None
    
    def _build_voting_classifier(self, X_ltf, X_htf, y):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–æ–ª–æ—Å—É—é—â–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            X_combined = pd.concat([X_ltf, X_htf], axis=1)
            
            # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏
            rf = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)
            lr = LogisticRegression(random_state=42, max_iter=1000)
            
            # Voting Classifier
            voting_model = VotingClassifier(
                estimators=[('rf', rf), ('lr', lr)],
                voting='soft'
            )
            
            voting_model.fit(X_combined, y)
            
            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            score = cross_val_score(voting_model, X_combined, y, cv=3, scoring='roc_auc').mean()
            
            return {
                'model': voting_model,
                'score': score,
                'features': X_combined.columns.tolist()
            }
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è voting classifier: {e}")
            return None
    
    def _build_stacked_model(self, X_ltf, X_htf, y):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ç–µ–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        
        try:
            # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            ltf_base = RandomForestClassifier(n_estimators=30, random_state=42, max_depth=4)
            htf_base = RandomForestClassifier(n_estimators=30, random_state=43, max_depth=4)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
            tscv = TimeSeriesSplit(n_splits=3)
            
            ltf_meta_features = np.zeros(len(y))
            htf_meta_features = np.zeros(len(y))
            
            for train_idx, val_idx in tscv.split(X_ltf):
                # LTF –º–æ–¥–µ–ª—å
                ltf_base.fit(X_ltf.iloc[train_idx], y.iloc[train_idx])
                ltf_pred = ltf_base.predict_proba(X_ltf.iloc[val_idx])[:, 1]
                ltf_meta_features[val_idx] = ltf_pred
                
                # HTF –º–æ–¥–µ–ª—å
                htf_base.fit(X_htf.iloc[train_idx], y.iloc[train_idx])
                htf_pred = htf_base.predict_proba(X_htf.iloc[val_idx])[:, 1]
                htf_meta_features[val_idx] = htf_pred
            
            # –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å
            meta_features = pd.DataFrame({
                'ltf_pred': ltf_meta_features,
                'htf_pred': htf_meta_features
            })
            
            meta_model = LogisticRegression(random_state=42)
            meta_model.fit(meta_features, y)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            ltf_base.fit(X_ltf, y)
            htf_base.fit(X_htf, y)
            
            return {
                'ltf_base': ltf_base,
                'htf_base': htf_base,
                'meta_model': meta_model,
                'meta_features': meta_features
            }
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è stacked model: {e}")
            return None
    
    def _build_meta_learner(self, X_ltf, X_htf, y):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–µ—Ç–∞-–æ–±—É—á–∞—é—â–µ–π—Å—è –º–æ–¥–µ–ª–∏"""
        
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            meta_data = pd.DataFrame({
                'ltf_activity': X_ltf.abs().sum(axis=1),
                'htf_activity': X_htf.abs().sum(axis=1),
                'ltf_diversity': X_ltf.std(axis=1),
                'htf_diversity': X_htf.std(axis=1),
                'combined_signal': (X_ltf.abs().sum(axis=1) + X_htf.abs().sum(axis=1)) / 2
            })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—ã–±–æ—Ä–æ—á–Ω–æ)
            if len(X_ltf.columns) > 10:
                top_ltf = X_ltf.iloc[:, :5]
            else:
                top_ltf = X_ltf
                
            if len(X_htf.columns) > 10:
                top_htf = X_htf.iloc[:, :5]
            else:
                top_htf = X_htf
            
            combined_features = pd.concat([meta_data, top_ltf, top_htf], axis=1)
            
            # –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å
            meta_model = RandomForestClassifier(
                n_estimators=100, 
                random_state=42, 
                max_depth=8,
                min_samples_split=10
            )
            
            meta_model.fit(combined_features, y)
            
            score = cross_val_score(meta_model, combined_features, y, cv=3, scoring='roc_auc').mean()
            
            return {
                'model': meta_model,
                'features': combined_features.columns.tolist(),
                'score': score
            }
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è meta learner: {e}")
            return None
    
    def _develop_adaptive_weighting(self):
        """–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è"""
        print("‚öñÔ∏è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è...")
        
        self.adaptive_weights = {}
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ù–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        self.adaptive_weights['volatility_based'] = {
            'description': '–í–µ—Å–∞ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞',
            'logic': {
                'low_volatility': {'ltf_weight': 0.3, 'htf_weight': 0.7},
                'medium_volatility': {'ltf_weight': 0.5, 'htf_weight': 0.5},
                'high_volatility': {'ltf_weight': 0.7, 'htf_weight': 0.3}
            },
            'rationale': '–í –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ LTF –±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã'
        }
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ù–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
        self.adaptive_weights['confidence_based'] = {
            'description': '–í–µ—Å–∞ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–π —Å–∏—Å—Ç–µ–º—ã',
            'logic': 'Weight = Confidence_score / (LTF_confidence + HTF_confidence)',
            'min_weight': 0.2,
            'max_weight': 0.8
        }
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.adaptive_weights['performance_based'] = {
            'description': '–í–µ—Å–∞ –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è –∫ –Ω–µ–¥–∞–≤–Ω–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
            'window': 20,  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–∏–≥–Ω–∞–ª–æ–≤
            'decay_factor': 0.95,  # —Å–Ω–∏–∂–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            'update_frequency': 5  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 —Å–∏–≥–Ω–∞–ª–æ–≤
        }
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –í—Ä–µ–º—è-–∑–∞–≤–∏—Å–∏–º—ã–µ –≤–µ—Å–∞
        self.adaptive_weights['time_based'] = {
            'description': '–í–µ—Å–∞ –º–µ–Ω—è—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏',
            'logic': {
                'market_open': {'ltf_weight': 0.7, 'htf_weight': 0.3},
                'mid_session': {'ltf_weight': 0.5, 'htf_weight': 0.5},
                'market_close': {'ltf_weight': 0.6, 'htf_weight': 0.4}
            }
        }
        
        print(f"   –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.adaptive_weights)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è")
    
    def _validate_all_scenarios(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞"""
        print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤...")
        
        self.scenario_validation = {}
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
        for scenario_name, scenario_config in self.scoring_scenarios.items():
            validation_result = self._validate_scenario(scenario_name, scenario_config)
            self.scenario_validation[scenario_name] = validation_result
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        for model_name, model_data in self.combined_models.items():
            if model_data:
                validation_result = self._validate_ensemble_model(model_name, model_data)
                self.scenario_validation[f'ensemble_{model_name}'] = validation_result
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
        best_scenario = self._find_best_scenario()
        self.scenario_validation['best_scenario'] = best_scenario
        
        print(f"   –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ {len(self.scenario_validation)} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤")
        print(f"   –õ—É—á—à–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π: {best_scenario['name']} (ROC-AUC: {best_scenario['score']:.3f})")
    
    def _validate_scenario(self, scenario_name, scenario_config):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        
        # –≠–º—É–ª—è—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        ltf_perf = self.ltf_results.get('validation', {}).get('roc_auc', 0)
        htf_perf = self.htf_results.get('validation', {}).get('roc_auc', 0)
        
        if scenario_config['ltf_weight'] == 'dynamic':
            # –î–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è –±–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ
            combined_score = (ltf_perf + htf_perf) / 2 + 0.05  # –ë–æ–Ω—É—Å –∑–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å
        elif scenario_config['ltf_weight'] == 'conditional':
            # –î–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
            combined_score = max(ltf_perf, htf_perf) * 0.9  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–∑–º
        else:
            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
            ltf_weight = float(scenario_config['ltf_weight'])
            htf_weight = float(scenario_config['htf_weight'])
            combined_score = ltf_perf * ltf_weight + htf_perf * htf_weight
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —à—É–º
        combined_score += np.random.normal(0, 0.02)
        combined_score = max(0.5, min(1.0, combined_score))
        
        return {
            'scenario': scenario_name,
            'estimated_roc_auc': combined_score,
            'estimated_accuracy': combined_score * 0.8 + 0.1,  # –ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
            'use_case': scenario_config['use_case'],
            'complexity': self._assess_scenario_complexity(scenario_config)
        }
    
    def _validate_ensemble_model(self, model_name, model_data):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        
        if 'score' in model_data:
            return {
                'scenario': f'ensemble_{model_name}',
                'estimated_roc_auc': model_data['score'],
                'estimated_accuracy': model_data['score'] * 0.8 + 0.1,
                'use_case': '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ',
                'complexity': 'high'
            }
        else:
            # –≠–º—É–ª—è—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –æ—Ü–µ–Ω–∫–∏
            ltf_perf = self.ltf_results.get('validation', {}).get('roc_auc', 0)
            htf_perf = self.htf_results.get('validation', {}).get('roc_auc', 0)
            ensemble_score = (ltf_perf + htf_perf) / 2 + 0.03  # –ù–µ–±–æ–ª—å—à–æ–π –±–æ–Ω—É—Å –∑–∞ –∞–Ω—Å–∞–º–±–ª—å
            
            return {
                'scenario': f'ensemble_{model_name}',
                'estimated_roc_auc': ensemble_score,
                'estimated_accuracy': ensemble_score * 0.8 + 0.1,
                'use_case': '–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ',
                'complexity': 'high'
            }
    
    def _assess_scenario_complexity(self, scenario_config):
        """–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        
        if scenario_config['ltf_weight'] in ['dynamic', 'conditional']:
            return 'high'
        elif isinstance(scenario_config['ltf_weight'], str):
            return 'medium'
        else:
            return 'low'
    
    def _find_best_scenario(self):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        
        best_score = 0
        best_scenario = {'name': 'none', 'score': 0}
        
        for scenario_name, validation in self.scenario_validation.items():
            if scenario_name == 'best_scenario':
                continue
                
            score = validation.get('estimated_roc_auc', 0)
            
            if score > best_score:
                best_score = score
                best_scenario = {
                    'name': scenario_name,
                    'score': score,
                    'details': validation
                }
        
        return best_scenario
    
    def _generate_final_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        print("üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        
        self.final_recommendations = {
            'summary': self._create_summary(),
            'scenario_rankings': self._rank_scenarios(),
            'implementation_guide': self._create_implementation_guide(),
            'risk_warnings': self._identify_risks(),
            'optimization_suggestions': self._suggest_optimizations()
        }
        
        print("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã")
    
    def _create_summary(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–∫–∏"""
        
        best_scenario = self.scenario_validation.get('best_scenario', {})
        compatibility = self.combination_analysis.get('compatibility', {})
        
        return {
            'best_scenario': best_scenario.get('name', 'unknown'),
            'best_score': best_scenario.get('score', 0),
            'ltf_performance': self.ltf_results.get('validation', {}).get('roc_auc', 0),
            'htf_performance': self.htf_results.get('validation', {}).get('roc_auc', 0),
            'synergy_potential': compatibility.get('synergy_potential', 0),
            'total_scenarios_tested': len(self.scenario_validation) - 1  # -1 –¥–ª—è best_scenario
        }
    
    def _rank_scenarios(self):
        """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤"""
        
        rankings = []
        
        for scenario_name, validation in self.scenario_validation.items():
            if scenario_name == 'best_scenario':
                continue
                
            rankings.append({
                'scenario': scenario_name,
                'score': validation.get('estimated_roc_auc', 0),
                'accuracy': validation.get('estimated_accuracy', 0),
                'complexity': validation.get('complexity', 'unknown'),
                'use_case': validation.get('use_case', 'General')
            })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
        rankings.sort(key=lambda x: x['score'], reverse=True)
        
        return rankings
    
    def _create_implementation_guide(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏"""
        
        best_scenario = self.scenario_validation.get('best_scenario', {})
        best_name = best_scenario.get('name', 'balanced')
        
        if best_name in self.scoring_scenarios:
            scenario_config = self.scoring_scenarios[best_name]
            
            return {
                'recommended_scenario': best_name,
                'implementation_steps': [
                    f"1. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞: LTF={scenario_config.get('ltf_weight', 0.5)}, HTF={scenario_config.get('htf_weight', 0.5)}",
                    f"2. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É: {scenario_config.get('logic', 'Standard combination')}",
                    f"3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è: {scenario_config.get('use_case', 'General trading')}",
                    "4. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å VETO –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏",
                    "5. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
                ],
                'configuration': scenario_config
            }
        else:
            return {
                'recommended_scenario': 'balanced',
                'implementation_steps': [
                    "1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ 50/50",
                    "2. –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±–µ–∏—Ö —Å–∏—Å—Ç–µ–º",
                    "3. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"
                ]
            }
    
    def _identify_risks(self):
        """–í—ã—è–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤"""
        
        risks = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        ltf_roc = self.ltf_results.get('validation', {}).get('roc_auc', 0)
        htf_roc = self.htf_results.get('validation', {}).get('roc_auc', 0)
        
        if ltf_roc < 0.6:
            risks.append("LTF —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∏–∑–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        
        if htf_roc < 0.6:
            risks.append("HTF —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∏–∑–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        
        if abs(ltf_roc - htf_roc) > 0.3:
            risks.append("–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É LTF –∏ HTF –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω–µ—Ä–≥–∏–∏
        synergy = self.combination_analysis.get('compatibility', {}).get('synergy_potential', 0)
        if synergy < 0.5:
            risks.append("–ù–∏–∑–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Å–∏–Ω–µ—Ä–≥–∏–∏ –º–µ–∂–¥—É —Å–∏—Å—Ç–µ–º–∞–º–∏")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        best_scenario = self.scenario_validation.get('best_scenario', {})
        if best_scenario.get('details', {}).get('complexity') == 'high':
            risks.append("–õ—É—á—à–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏")
        
        return risks
    
    def _suggest_optimizations(self):
        """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        suggestions = []
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        ltf_roc = self.ltf_results.get('validation', {}).get('roc_auc', 0)
        htf_roc = self.htf_results.get('validation', {}).get('roc_auc', 0)
        
        if ltf_roc > htf_roc + 0.1:
            suggestions.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ LTF —Å–∏—Å—Ç–µ–º—ã")
        elif htf_roc > ltf_roc + 0.1:
            suggestions.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ HTF —Å–∏—Å—Ç–µ–º—ã")
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ VETO –ø—Ä–∞–≤–∏–ª
        if self.veto_rules:
            suggestions.append("–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ VETO –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏
        suggestions.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è")
        suggestions.append("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        return suggestions
    
    def save_combined_analysis(self, output_dir="results/combined_scoring"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        with open(output_path / "final_recommendations.json", 'w') as f:
            json.dump(self.final_recommendations, f, indent=2, default=str)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        scenario_df = pd.DataFrame([
            v for k, v in self.scenario_validation.items() if k != 'best_scenario'
        ])
        scenario_df.to_csv(output_path / "scenario_validation.csv", index=False)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        with open(output_path / "scoring_scenarios.json", 'w') as f:
            json.dump(self.scoring_scenarios, f, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤
        with open(output_path / "adaptive_weights.json", 'w') as f:
            json.dump(self.adaptive_weights, f, indent=2)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self._create_combined_report(output_path)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        self._create_combined_visualizations(output_path)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
    
    def _create_combined_report(self, output_path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É"""
        
        report_lines = [
            "–ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –°–ö–û–†–ò–ù–ì LTF + HTF - –û–¢–ß–ï–¢",
            "=" * 60,
            f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "–°–í–û–î–ö–ê:",
        ]
        
        summary = self.final_recommendations.get('summary', {})
        report_lines.extend([
            f"–õ—É—á—à–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π: {summary.get('best_scenario', 'unknown')}",
            f"–õ—É—á—à–∏–π —Å–∫–æ—Ä: {summary.get('best_score', 0):.3f}",
            f"LTF –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {summary.get('ltf_performance', 0):.3f}",
            f"HTF –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {summary.get('htf_performance', 0):.3f}",
            f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Å–∏–Ω–µ—Ä–≥–∏–∏: {summary.get('synergy_potential', 0):.3f}",
            f"–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤: {summary.get('total_scenarios_tested', 0)}",
            "",
        ])
        
        # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        rankings = self.final_recommendations.get('scenario_rankings', [])
        if rankings:
            report_lines.extend([
                "–†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï –°–¶–ï–ù–ê–†–ò–ï–í:",
            ])
            for i, scenario in enumerate(rankings[:5], 1):
                report_lines.append(
                    f"{i}. {scenario['scenario']}: {scenario['score']:.3f} "
                    f"({scenario['complexity']} complexity)"
                )
            report_lines.append("")
        
        # –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        impl_guide = self.final_recommendations.get('implementation_guide', {})
        if impl_guide:
            report_lines.extend([
                "–†–£–ö–û–í–û–î–°–¢–í–û –ü–û –†–ï–ê–õ–ò–ó–ê–¶–ò–ò:",
                f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π: {impl_guide.get('recommended_scenario', 'unknown')}",
                "",
                "–®–∞–≥–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:",
            ])
            for step in impl_guide.get('implementation_steps', []):
                report_lines.append(f"  {step}")
            report_lines.append("")
        
        # –†–∏—Å–∫–∏
        risks = self.final_recommendations.get('risk_warnings', [])
        if risks:
            report_lines.extend([
                "–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø –û –†–ò–°–ö–ê–•:",
            ])
            for risk in risks:
                report_lines.append(f"  ‚ö†Ô∏è {risk}")
            report_lines.append("")
        
        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        optimizations = self.final_recommendations.get('optimization_suggestions', [])
        if optimizations:
            report_lines.extend([
                "–ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:",
            ])
            for suggestion in optimizations:
                report_lines.append(f"  üí° {suggestion}")
            report_lines.append("")
        
        report_lines.extend([
            "–§–ê–ô–õ–´ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:",
            "final_recommendations.json - –ø–æ–ª–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
            "scenario_validation.csv - –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
            "scoring_scenarios.json - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
            "adaptive_weights.json - —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è",
            "scenario_comparison.png - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤",
            "",
            "=" * 60
        ])
        
        with open(output_path / "combined_scoring_report.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
    
    def _create_combined_visualizations(self, output_path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        plt.style.use('default')
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        rankings = self.final_recommendations.get('scenario_rankings', [])
        
        if rankings:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
            scenarios = [r['scenario'][:15] for r in rankings[:8]]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –Ω–∞–∑–≤–∞–Ω–∏–π
            scores = [r['score'] for r in rankings[:8]]
            
            bars = ax1.bar(range(len(scenarios)), scores, 
                          color=plt.cm.viridis(np.linspace(0, 1, len(scenarios))))
            
            ax1.set_xlabel('–°—Ü–µ–Ω–∞—Ä–∏–∏')
            ax1.set_ylabel('ROC-AUC Score')
            ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤')
            ax1.set_xticks(range(len(scenarios)))
            ax1.set_xticklabels(scenarios, rotation=45, ha='right')
            ax1.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for bar, score in zip(bars, scores):
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{score:.3f}', ha='center', va='bottom', fontsize=9)
            
            # –°–ª–æ–∂–Ω–æ—Å—Ç—å vs –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            complexities = [r['complexity'] for r in rankings[:8]]
            complexity_numeric = [{'low': 1, 'medium': 2, 'high': 3}.get(c, 2) for c in complexities]
            
            scatter = ax2.scatter(complexity_numeric, scores, 
                                s=[100 + s*200 for s in scores],  # –†–∞–∑–º–µ—Ä –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                                c=scores, cmap='viridis', alpha=0.7)
            
            ax2.set_xlabel('–°–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏')
            ax2.set_ylabel('ROC-AUC Score')
            ax2.set_title('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å vs –°–ª–æ–∂–Ω–æ—Å—Ç—å')
            ax2.set_xticks([1, 2, 3])
            ax2.set_xticklabels(['–ù–∏–∑–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–í—ã—Å–æ–∫–∞—è'])
            ax2.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
            for i, scenario in enumerate(scenarios):
                ax2.annotate(scenario, (complexity_numeric[i], scores[i]), 
                           xytext=(5, 5), textcoords='offset points', fontsize=8)
            
            plt.tight_layout()
            plt.savefig(output_path / "scenario_comparison.png", dpi=300, bbox_inches='tight')
            plt.close()


def main():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–æ—Ä–µ—Ä–∞"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞...")
    
    # –≠–º—É–ª—è—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LTF –∏ HTF
    ltf_results = {
        'validation': {'roc_auc': 0.75, 'accuracy': 0.68},
        'features': pd.DataFrame(np.random.randn(100, 20)),
        'temporal_lags': {
            'group_1': {'mean_lag': 2.5, 'activation_rate': 0.6},
            'group_2': {'mean_lag': 3.1, 'activation_rate': 0.4}
        },
        'events_rate': 0.25
    }
    
    htf_results = {
        'validation': {'roc_auc': 0.72, 'accuracy': 0.65},
        'features': pd.DataFrame(np.random.randn(100, 15)),
        'temporal_lags': {
            'group_1': {'mean_lag': 5.2, 'activation_rate': 0.3},
            'group_2': {'mean_lag': 4.8, 'activation_rate': 0.5}
        },
        'events_rate': 0.18
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –≤ features –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    ltf_results['features']['is_event'] = (np.random.randn(100) > 1).astype(int)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–æ—Ä–µ—Ä–∞
    combined_scorer = CombinedScorer()
    recommendations = combined_scorer.create_combined_scoring_system(
        ltf_results, htf_results
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    combined_scorer.save_combined_analysis("results/test_combined_scoring")
    
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print(f"–õ—É—á—à–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–π: {recommendations['summary']['best_scenario']}")


if __name__ == "__main__":
    main()